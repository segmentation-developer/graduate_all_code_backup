
Namespace(T=4, base_lr=0.01, batch_size=4, consistency=1.0, consistency_rampup=0.0, consistency_type='mse', deterministic=1, ema_decay=0.99, exp='kfold/GDT-MT', fold=5, gpu='4', labeled_bs=2, labeled_num=28, max_iterations=30000, model='vnet_3D_96_32', num_classes=2, patch_size=[96, 96, 96], root_path='/data/sohui/BraTS/data/BraTs2019', seed=1337, total_labeled_num=268)
total 268 samples
14 iterations per epoch
  0%|                                        | 0/2143 [00:00<?, ?it/s]
iteration 1 : loss : 0.741809, loss_ce: 0.501231, loss_dice: 0.401281
iteration 2 : loss : 0.632794, loss_ce: 0.586590, loss_dice: 0.401797
iteration 3 : loss : 0.821997, loss_ce: 0.585466, loss_dice: 0.466406
iteration 4 : loss : 0.670379, loss_ce: 0.592758, loss_dice: 0.447507
iteration 5 : loss : 0.839059, loss_ce: 0.585462, loss_dice: 0.501698
iteration 6 : loss : 0.656351, loss_ce: 0.447662, loss_dice: 0.432361
iteration 7 : loss : 0.682967, loss_ce: 0.460831, loss_dice: 0.433665
iteration 8 : loss : 0.511142, loss_ce: 0.412170, loss_dice: 0.318478
iteration 9 : loss : 0.440474, loss_ce: 0.371254, loss_dice: 0.292744
iteration 10 : loss : 0.485680, loss_ce: 0.416256, loss_dice: 0.281087
iteration 11 : loss : 0.489566, loss_ce: 0.430102, loss_dice: 0.368829
iteration 12 : loss : 0.284379, loss_ce: 0.271555, loss_dice: 0.167143

  0%|                             | 1/2143 [00:30<18:13:52, 30.64s/it]
iteration 14 : loss : 0.332924, loss_ce: 0.279275, loss_dice: 0.315787
iteration 15 : loss : 0.333019, loss_ce: 0.339029, loss_dice: 0.201002
iteration 16 : loss : 0.359978, loss_ce: 0.327354, loss_dice: 0.243928
iteration 17 : loss : 0.368191, loss_ce: 0.328148, loss_dice: 0.323071
iteration 18 : loss : 0.316440, loss_ce: 0.258001, loss_dice: 0.220756
iteration 19 : loss : 0.255009, loss_ce: 0.266755, loss_dice: 0.157857
iteration 20 : loss : 0.370460, loss_ce: 0.330683, loss_dice: 0.275109
iteration 21 : loss : 0.301781, loss_ce: 0.323517, loss_dice: 0.214846
iteration 22 : loss : 0.278767, loss_ce: 0.209560, loss_dice: 0.273195
iteration 23 : loss : 0.296471, loss_ce: 0.263369, loss_dice: 0.249266
iteration 24 : loss : 0.202712, loss_ce: 0.173036, loss_dice: 0.150527
iteration 25 : loss : 0.327540, loss_ce: 0.305381, loss_dice: 0.245044
iteration 26 : loss : 0.268070, loss_ce: 0.244357, loss_dice: 0.229558
iteration 27 : loss : 0.351897, loss_ce: 0.312400, loss_dice: 0.243457

  0%|                             | 2/2143 [01:00<17:58:59, 30.24s/it]
iteration 29 : loss : 0.209774, loss_ce: 0.168483, loss_dice: 0.180965
iteration 30 : loss : 0.257561, loss_ce: 0.266196, loss_dice: 0.167320
iteration 31 : loss : 0.210196, loss_ce: 0.220742, loss_dice: 0.125460
iteration 32 : loss : 0.204010, loss_ce: 0.172233, loss_dice: 0.151023
iteration 33 : loss : 0.294236, loss_ce: 0.252766, loss_dice: 0.262473
iteration 34 : loss : 0.241087, loss_ce: 0.216957, loss_dice: 0.184426
iteration 35 : loss : 0.190279, loss_ce: 0.151889, loss_dice: 0.121060
iteration 36 : loss : 0.256514, loss_ce: 0.226327, loss_dice: 0.201429
iteration 37 : loss : 0.228555, loss_ce: 0.112883, loss_dice: 0.297988
iteration 38 : loss : 0.190038, loss_ce: 0.189049, loss_dice: 0.106709
iteration 39 : loss : 0.147146, loss_ce: 0.143107, loss_dice: 0.062979
iteration 40 : loss : 0.229183, loss_ce: 0.212401, loss_dice: 0.162247
iteration 41 : loss : 0.242382, loss_ce: 0.176270, loss_dice: 0.202016

  0%|                             | 3/2143 [01:30<17:48:26, 29.96s/it]
iteration 43 : loss : 0.162975, loss_ce: 0.130469, loss_dice: 0.106526
iteration 44 : loss : 0.129037, loss_ce: 0.086965, loss_dice: 0.102193
iteration 45 : loss : 0.189292, loss_ce: 0.143676, loss_dice: 0.178215
iteration 46 : loss : 0.230325, loss_ce: 0.206768, loss_dice: 0.199347
iteration 47 : loss : 0.272484, loss_ce: 0.186413, loss_dice: 0.270749
iteration 48 : loss : 0.208375, loss_ce: 0.147581, loss_dice: 0.198100
iteration 49 : loss : 0.225326, loss_ce: 0.136851, loss_dice: 0.237968
iteration 50 : loss : 0.189257, loss_ce: 0.149396, loss_dice: 0.137114
iteration 51 : loss : 0.234773, loss_ce: 0.203246, loss_dice: 0.170348
iteration 52 : loss : 0.164389, loss_ce: 0.137587, loss_dice: 0.125177
iteration 53 : loss : 0.258488, loss_ce: 0.231123, loss_dice: 0.203870
iteration 54 : loss : 0.139452, loss_ce: 0.130618, loss_dice: 0.065106

  0%|                             | 4/2143 [02:00<17:58:52, 30.26s/it]
iteration 56 : loss : 0.218654, loss_ce: 0.178138, loss_dice: 0.193163
iteration 57 : loss : 0.185354, loss_ce: 0.177353, loss_dice: 0.127890
iteration 58 : loss : 0.273359, loss_ce: 0.179404, loss_dice: 0.241497
iteration 59 : loss : 0.214803, loss_ce: 0.229029, loss_dice: 0.122216
iteration 60 : loss : 0.209677, loss_ce: 0.193404, loss_dice: 0.153071
iteration 61 : loss : 0.096028, loss_ce: 0.065571, loss_dice: 0.071923
iteration 62 : loss : 0.217979, loss_ce: 0.175865, loss_dice: 0.194744
iteration 63 : loss : 0.116564, loss_ce: 0.101954, loss_dice: 0.089422
iteration 64 : loss : 0.147682, loss_ce: 0.140150, loss_dice: 0.097917
iteration 65 : loss : 0.136188, loss_ce: 0.078707, loss_dice: 0.146258
iteration 66 : loss : 0.144196, loss_ce: 0.150841, loss_dice: 0.092843
iteration 67 : loss : 0.115045, loss_ce: 0.097833, loss_dice: 0.051697
iteration 68 : loss : 0.130620, loss_ce: 0.121786, loss_dice: 0.074789

  0%|                             | 5/2143 [02:31<17:55:49, 30.19s/it]
iteration 70 : loss : 0.167529, loss_ce: 0.169520, loss_dice: 0.100646
iteration 71 : loss : 0.195950, loss_ce: 0.137736, loss_dice: 0.200815
iteration 72 : loss : 0.233738, loss_ce: 0.186935, loss_dice: 0.208342
iteration 73 : loss : 0.106996, loss_ce: 0.095323, loss_dice: 0.061509
iteration 74 : loss : 0.134618, loss_ce: 0.131051, loss_dice: 0.080480
iteration 75 : loss : 0.179593, loss_ce: 0.168374, loss_dice: 0.126247
iteration 76 : loss : 0.186373, loss_ce: 0.133037, loss_dice: 0.173920
iteration 77 : loss : 0.118358, loss_ce: 0.085600, loss_dice: 0.078648
iteration 78 : loss : 0.265156, loss_ce: 0.121788, loss_dice: 0.341262
iteration 79 : loss : 0.237765, loss_ce: 0.149610, loss_dice: 0.258366
iteration 80 : loss : 0.219978, loss_ce: 0.198771, loss_dice: 0.169552
iteration 81 : loss : 0.136908, loss_ce: 0.095471, loss_dice: 0.122885
iteration 82 : loss : 0.146442, loss_ce: 0.148323, loss_dice: 0.073977

  0%|                             | 6/2143 [03:01<17:56:37, 30.23s/it]
iteration 84 : loss : 0.145555, loss_ce: 0.068523, loss_dice: 0.173920
iteration 85 : loss : 0.214322, loss_ce: 0.109533, loss_dice: 0.256032
iteration 86 : loss : 0.155902, loss_ce: 0.148236, loss_dice: 0.108219
iteration 87 : loss : 0.178543, loss_ce: 0.127898, loss_dice: 0.157376
iteration 88 : loss : 0.152732, loss_ce: 0.174427, loss_dice: 0.079449
iteration 89 : loss : 0.138807, loss_ce: 0.091721, loss_dice: 0.127773
iteration 90 : loss : 0.150813, loss_ce: 0.089113, loss_dice: 0.152089
iteration 91 : loss : 0.110364, loss_ce: 0.103314, loss_dice: 0.061949
iteration 92 : loss : 0.079773, loss_ce: 0.064475, loss_dice: 0.044543
iteration 93 : loss : 0.261049, loss_ce: 0.175279, loss_dice: 0.279158
iteration 94 : loss : 0.098657, loss_ce: 0.074913, loss_dice: 0.076654
iteration 95 : loss : 0.125167, loss_ce: 0.096754, loss_dice: 0.093273
iteration 96 : loss : 0.238327, loss_ce: 0.149091, loss_dice: 0.272708

  0%|                             | 7/2143 [03:31<17:57:31, 30.27s/it]
iteration 98 : loss : 0.111625, loss_ce: 0.085317, loss_dice: 0.077269
iteration 99 : loss : 0.102355, loss_ce: 0.079601, loss_dice: 0.076079
iteration 100 : loss : 0.150151, loss_ce: 0.093033, loss_dice: 0.159726
iteration 101 : loss : 0.231460, loss_ce: 0.228299, loss_dice: 0.186450
iteration 102 : loss : 0.085170, loss_ce: 0.067988, loss_dice: 0.056871
iteration 103 : loss : 0.143229, loss_ce: 0.102230, loss_dice: 0.143284
iteration 104 : loss : 0.197268, loss_ce: 0.110569, loss_dice: 0.231803
iteration 105 : loss : 0.209184, loss_ce: 0.170648, loss_dice: 0.163626
iteration 106 : loss : 0.149729, loss_ce: 0.110976, loss_dice: 0.120093
iteration 107 : loss : 0.322670, loss_ce: 0.135547, loss_dice: 0.450059
iteration 108 : loss : 0.178389, loss_ce: 0.137554, loss_dice: 0.160405
iteration 109 : loss : 0.133881, loss_ce: 0.108210, loss_dice: 0.098103
iteration 110 : loss : 0.218902, loss_ce: 0.219801, loss_dice: 0.137158

  0%|                             | 8/2143 [04:01<17:53:26, 30.17s/it]
iteration 112 : loss : 0.130873, loss_ce: 0.101510, loss_dice: 0.097261
iteration 113 : loss : 0.160175, loss_ce: 0.108115, loss_dice: 0.171458
iteration 114 : loss : 0.118192, loss_ce: 0.104645, loss_dice: 0.085779
iteration 115 : loss : 0.294910, loss_ce: 0.319742, loss_dice: 0.199613
iteration 116 : loss : 0.283605, loss_ce: 0.239629, loss_dice: 0.244273
iteration 117 : loss : 0.066812, loss_ce: 0.038749, loss_dice: 0.025059
iteration 118 : loss : 0.130086, loss_ce: 0.132502, loss_dice: 0.083490
iteration 119 : loss : 0.114853, loss_ce: 0.107320, loss_dice: 0.077192
iteration 120 : loss : 0.290474, loss_ce: 0.294038, loss_dice: 0.228698
iteration 121 : loss : 0.138215, loss_ce: 0.106032, loss_dice: 0.121978
iteration 122 : loss : 0.098008, loss_ce: 0.081841, loss_dice: 0.051525
iteration 123 : loss : 0.168727, loss_ce: 0.157085, loss_dice: 0.123901
iteration 124 : loss : 0.173911, loss_ce: 0.143666, loss_dice: 0.142890

  0%|                             | 9/2143 [04:31<17:54:05, 30.20s/it]
iteration 126 : loss : 0.083602, loss_ce: 0.059505, loss_dice: 0.056495
iteration 127 : loss : 0.233219, loss_ce: 0.237083, loss_dice: 0.160360
iteration 128 : loss : 0.110462, loss_ce: 0.071336, loss_dice: 0.090897
iteration 129 : loss : 0.169134, loss_ce: 0.148699, loss_dice: 0.115503
iteration 130 : loss : 0.115608, loss_ce: 0.098679, loss_dice: 0.077992
iteration 131 : loss : 0.173882, loss_ce: 0.085462, loss_dice: 0.203207
iteration 132 : loss : 0.230830, loss_ce: 0.157913, loss_dice: 0.238909
iteration 133 : loss : 0.241864, loss_ce: 0.217467, loss_dice: 0.203082
iteration 134 : loss : 0.093513, loss_ce: 0.083586, loss_dice: 0.047162
iteration 135 : loss : 0.090785, loss_ce: 0.058790, loss_dice: 0.039161
iteration 136 : loss : 0.139817, loss_ce: 0.106908, loss_dice: 0.122976
iteration 137 : loss : 0.101553, loss_ce: 0.088720, loss_dice: 0.067110
iteration 138 : loss : 0.250502, loss_ce: 0.219361, loss_dice: 0.212690

  0%|▏                           | 10/2143 [05:02<18:00:58, 30.41s/it]
iteration 140 : loss : 0.186333, loss_ce: 0.137702, loss_dice: 0.182034
iteration 141 : loss : 0.115878, loss_ce: 0.070627, loss_dice: 0.099457
iteration 142 : loss : 0.256532, loss_ce: 0.143023, loss_dice: 0.296736
iteration 143 : loss : 0.066281, loss_ce: 0.032954, loss_dice: 0.050256
iteration 144 : loss : 0.114182, loss_ce: 0.095458, loss_dice: 0.084224
iteration 145 : loss : 0.226448, loss_ce: 0.242572, loss_dice: 0.138299
iteration 146 : loss : 0.101263, loss_ce: 0.061133, loss_dice: 0.096884
iteration 147 : loss : 0.227949, loss_ce: 0.168508, loss_dice: 0.231903
iteration 148 : loss : 0.177959, loss_ce: 0.157568, loss_dice: 0.109984
iteration 149 : loss : 0.093858, loss_ce: 0.060617, loss_dice: 0.081082
iteration 150 : loss : 0.126674, loss_ce: 0.124720, loss_dice: 0.072803
iteration 151 : loss : 0.219307, loss_ce: 0.187090, loss_dice: 0.183002
iteration 152 : loss : 0.086197, loss_ce: 0.083895, loss_dice: 0.050140

  1%|▏                           | 11/2143 [05:33<18:06:29, 30.58s/it]
iteration 154 : loss : 0.153895, loss_ce: 0.103481, loss_dice: 0.145654
iteration 155 : loss : 0.084550, loss_ce: 0.066241, loss_dice: 0.054371
iteration 156 : loss : 0.234834, loss_ce: 0.232557, loss_dice: 0.173593
iteration 157 : loss : 0.109131, loss_ce: 0.078932, loss_dice: 0.082865
iteration 158 : loss : 0.186785, loss_ce: 0.178157, loss_dice: 0.111637
iteration 159 : loss : 0.185570, loss_ce: 0.138480, loss_dice: 0.162377
iteration 160 : loss : 0.093005, loss_ce: 0.072783, loss_dice: 0.071012
iteration 161 : loss : 0.120150, loss_ce: 0.089948, loss_dice: 0.109410
iteration 162 : loss : 0.370885, loss_ce: 0.087759, loss_dice: 0.506081
iteration 163 : loss : 0.164129, loss_ce: 0.124181, loss_dice: 0.166101
iteration 164 : loss : 0.103576, loss_ce: 0.092799, loss_dice: 0.066523
iteration 165 : loss : 0.181514, loss_ce: 0.142815, loss_dice: 0.161818
iteration 166 : loss : 0.122411, loss_ce: 0.102121, loss_dice: 0.091099

  1%|▏                           | 12/2143 [06:03<17:57:38, 30.34s/it]
iteration 168 : loss : 0.095024, loss_ce: 0.045829, loss_dice: 0.103365
iteration 169 : loss : 0.136600, loss_ce: 0.124220, loss_dice: 0.093101
iteration 170 : loss : 0.128946, loss_ce: 0.138123, loss_dice: 0.069236
iteration 171 : loss : 0.107548, loss_ce: 0.103074, loss_dice: 0.063610
iteration 172 : loss : 0.116064, loss_ce: 0.088170, loss_dice: 0.089866
iteration 173 : loss : 0.151389, loss_ce: 0.120461, loss_dice: 0.127486
iteration 174 : loss : 0.074374, loss_ce: 0.038506, loss_dice: 0.057645
iteration 175 : loss : 0.085169, loss_ce: 0.075499, loss_dice: 0.053519
iteration 176 : loss : 0.106168, loss_ce: 0.077372, loss_dice: 0.075874
iteration 177 : loss : 0.151241, loss_ce: 0.112868, loss_dice: 0.119750
iteration 178 : loss : 0.089378, loss_ce: 0.074176, loss_dice: 0.047597
iteration 179 : loss : 0.165327, loss_ce: 0.102212, loss_dice: 0.163176
iteration 180 : loss : 0.152450, loss_ce: 0.104520, loss_dice: 0.139591

  1%|▏                           | 13/2143 [06:34<17:58:57, 30.39s/it]
iteration 182 : loss : 0.203744, loss_ce: 0.177507, loss_dice: 0.187367
iteration 183 : loss : 0.114805, loss_ce: 0.114177, loss_dice: 0.066357
iteration 184 : loss : 0.170740, loss_ce: 0.077974, loss_dice: 0.212154
iteration 185 : loss : 0.230959, loss_ce: 0.151427, loss_dice: 0.252733
iteration 186 : loss : 0.174254, loss_ce: 0.120273, loss_dice: 0.162323
iteration 187 : loss : 0.188042, loss_ce: 0.147700, loss_dice: 0.166828
iteration 188 : loss : 0.114068, loss_ce: 0.084963, loss_dice: 0.091928
iteration 189 : loss : 0.087635, loss_ce: 0.077827, loss_dice: 0.059788
iteration 190 : loss : 0.134541, loss_ce: 0.049601, loss_dice: 0.161594
iteration 191 : loss : 0.260376, loss_ce: 0.144446, loss_dice: 0.311016
iteration 192 : loss : 0.253274, loss_ce: 0.218649, loss_dice: 0.214804
iteration 193 : loss : 0.109608, loss_ce: 0.050774, loss_dice: 0.129641
iteration 194 : loss : 0.092181, loss_ce: 0.080129, loss_dice: 0.052069

  1%|▏                           | 14/2143 [07:03<17:53:43, 30.26s/it]
iteration 196 : loss : 0.140403, loss_ce: 0.115335, loss_dice: 0.114145
iteration 197 : loss : 0.149413, loss_ce: 0.110558, loss_dice: 0.107662
iteration 198 : loss : 0.193174, loss_ce: 0.149367, loss_dice: 0.186438
iteration 199 : loss : 0.135598, loss_ce: 0.127691, loss_dice: 0.083888
  0%|                                                                                                                                                                                                            | 0/67 [00:00<?, ?it/s]
iteration 200 : loss : 0.178241, loss_ce: 0.162996, loss_dice: 0.131842


































































 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 66/67 [04:04<00:03,  3.14s/it]
Validation end

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 201 : loss : 0.125727, loss_ce: 0.115546, loss_dice: 0.077458
iteration 202 : loss : 0.144204, loss_ce: 0.085992, loss_dice: 0.144979
iteration 203 : loss : 0.131840, loss_ce: 0.115805, loss_dice: 0.088337
iteration 204 : loss : 0.237006, loss_ce: 0.148596, loss_dice: 0.280048
iteration 205 : loss : 0.071615, loss_ce: 0.057930, loss_dice: 0.044514
iteration 206 : loss : 0.170709, loss_ce: 0.084216, loss_dice: 0.205995
iteration 207 : loss : 0.072820, loss_ce: 0.042083, loss_dice: 0.053780
iteration 208 : loss : 0.168807, loss_ce: 0.135201, loss_dice: 0.145964
iteration 209 : loss : 0.124514, loss_ce: 0.056161, loss_dice: 0.146700

  1%|▏                          | 15/2143 [11:41<62:00:40, 104.91s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 211 : loss : 0.194360, loss_ce: 0.151912, loss_dice: 0.191535
iteration 212 : loss : 0.097087, loss_ce: 0.064423, loss_dice: 0.077930
iteration 213 : loss : 0.347537, loss_ce: 0.339370, loss_dice: 0.264527
iteration 214 : loss : 0.072043, loss_ce: 0.044384, loss_dice: 0.052256
iteration 215 : loss : 0.213990, loss_ce: 0.147247, loss_dice: 0.221657
iteration 216 : loss : 0.132908, loss_ce: 0.074262, loss_dice: 0.153887
iteration 217 : loss : 0.171293, loss_ce: 0.178079, loss_dice: 0.096307
iteration 218 : loss : 0.101325, loss_ce: 0.092990, loss_dice: 0.058453
iteration 219 : loss : 0.125551, loss_ce: 0.106088, loss_dice: 0.089939
iteration 220 : loss : 0.104475, loss_ce: 0.062888, loss_dice: 0.100580
iteration 221 : loss : 0.169630, loss_ce: 0.107621, loss_dice: 0.187786
iteration 222 : loss : 0.186521, loss_ce: 0.137418, loss_dice: 0.183948
iteration 223 : loss : 0.100397, loss_ce: 0.087467, loss_dice: 0.060847

  1%|▏                           | 16/2143 [12:11<48:34:57, 82.23s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 225 : loss : 0.150684, loss_ce: 0.138272, loss_dice: 0.080909
iteration 226 : loss : 0.102922, loss_ce: 0.073190, loss_dice: 0.081425
iteration 227 : loss : 0.154584, loss_ce: 0.136187, loss_dice: 0.117486
iteration 228 : loss : 0.158548, loss_ce: 0.122969, loss_dice: 0.138249
iteration 229 : loss : 0.151838, loss_ce: 0.108468, loss_dice: 0.137457
iteration 230 : loss : 0.307761, loss_ce: 0.270020, loss_dice: 0.297863
iteration 231 : loss : 0.094614, loss_ce: 0.078972, loss_dice: 0.052147
iteration 232 : loss : 0.118606, loss_ce: 0.034717, loss_dice: 0.148584
iteration 233 : loss : 0.117086, loss_ce: 0.072796, loss_dice: 0.112191
iteration 234 : loss : 0.098731, loss_ce: 0.069965, loss_dice: 0.067156
iteration 235 : loss : 0.089588, loss_ce: 0.050347, loss_dice: 0.074170
iteration 236 : loss : 0.204463, loss_ce: 0.158445, loss_dice: 0.173208
iteration 237 : loss : 0.339493, loss_ce: 0.212949, loss_dice: 0.377173

  1%|▏                           | 17/2143 [12:41<39:18:30, 66.56s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 239 : loss : 0.225499, loss_ce: 0.147544, loss_dice: 0.237684
iteration 240 : loss : 0.121127, loss_ce: 0.130133, loss_dice: 0.065091
iteration 241 : loss : 0.122071, loss_ce: 0.063213, loss_dice: 0.122951
iteration 242 : loss : 0.181567, loss_ce: 0.124526, loss_dice: 0.188412
iteration 243 : loss : 0.082667, loss_ce: 0.058248, loss_dice: 0.057961
iteration 244 : loss : 0.144624, loss_ce: 0.100132, loss_dice: 0.120863
iteration 245 : loss : 0.138599, loss_ce: 0.073933, loss_dice: 0.146181
iteration 246 : loss : 0.128795, loss_ce: 0.050356, loss_dice: 0.153685
iteration 247 : loss : 0.170496, loss_ce: 0.151283, loss_dice: 0.123242
iteration 248 : loss : 0.135870, loss_ce: 0.089500, loss_dice: 0.128427
iteration 249 : loss : 0.285490, loss_ce: 0.273577, loss_dice: 0.225802
iteration 250 : loss : 0.087664, loss_ce: 0.066056, loss_dice: 0.061931
iteration 251 : loss : 0.090888, loss_ce: 0.062021, loss_dice: 0.068328

  1%|▏                           | 18/2143 [13:11<32:51:46, 55.67s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 253 : loss : 0.127461, loss_ce: 0.119634, loss_dice: 0.069626
iteration 254 : loss : 0.163675, loss_ce: 0.121962, loss_dice: 0.142973
iteration 255 : loss : 0.072675, loss_ce: 0.054669, loss_dice: 0.036563
iteration 256 : loss : 0.127445, loss_ce: 0.110405, loss_dice: 0.093295
iteration 257 : loss : 0.155177, loss_ce: 0.161652, loss_dice: 0.080469
iteration 258 : loss : 0.118157, loss_ce: 0.093473, loss_dice: 0.092307
iteration 259 : loss : 0.247383, loss_ce: 0.222279, loss_dice: 0.207796
iteration 260 : loss : 0.146596, loss_ce: 0.096396, loss_dice: 0.138355
iteration 261 : loss : 0.416450, loss_ce: 0.308287, loss_dice: 0.472174
iteration 262 : loss : 0.099099, loss_ce: 0.051458, loss_dice: 0.092119
iteration 263 : loss : 0.252020, loss_ce: 0.111931, loss_dice: 0.334359
iteration 264 : loss : 0.151338, loss_ce: 0.120179, loss_dice: 0.118045

  1%|▏                           | 19/2143 [13:41<28:14:45, 47.87s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 266 : loss : 0.058194, loss_ce: 0.038397, loss_dice: 0.035516
iteration 267 : loss : 0.245479, loss_ce: 0.132037, loss_dice: 0.310867
iteration 268 : loss : 0.172179, loss_ce: 0.177972, loss_dice: 0.116004
iteration 269 : loss : 0.165825, loss_ce: 0.135771, loss_dice: 0.129922
iteration 270 : loss : 0.087010, loss_ce: 0.062310, loss_dice: 0.057400
iteration 271 : loss : 0.088765, loss_ce: 0.056123, loss_dice: 0.028374
iteration 272 : loss : 0.086000, loss_ce: 0.063057, loss_dice: 0.062578
iteration 273 : loss : 0.097367, loss_ce: 0.070927, loss_dice: 0.074722
iteration 274 : loss : 0.156802, loss_ce: 0.128210, loss_dice: 0.126097
iteration 275 : loss : 0.101032, loss_ce: 0.055712, loss_dice: 0.105788
iteration 276 : loss : 0.085640, loss_ce: 0.063034, loss_dice: 0.068267
iteration 277 : loss : 0.304818, loss_ce: 0.278386, loss_dice: 0.257356
iteration 278 : loss : 0.097061, loss_ce: 0.045256, loss_dice: 0.064411

  1%|▎                           | 20/2143 [14:11<25:00:43, 42.41s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 280 : loss : 0.209288, loss_ce: 0.198147, loss_dice: 0.155170
iteration 281 : loss : 0.121029, loss_ce: 0.091929, loss_dice: 0.098709
iteration 282 : loss : 0.280786, loss_ce: 0.111955, loss_dice: 0.385396
iteration 283 : loss : 0.201123, loss_ce: 0.210964, loss_dice: 0.130858
iteration 284 : loss : 0.362296, loss_ce: 0.436162, loss_dice: 0.199304
iteration 285 : loss : 0.134296, loss_ce: 0.107004, loss_dice: 0.113294
iteration 286 : loss : 0.214139, loss_ce: 0.176053, loss_dice: 0.195560
iteration 287 : loss : 0.074867, loss_ce: 0.047731, loss_dice: 0.054918
iteration 288 : loss : 0.135350, loss_ce: 0.130248, loss_dice: 0.082695
iteration 289 : loss : 0.168510, loss_ce: 0.134480, loss_dice: 0.147230
iteration 290 : loss : 0.059144, loss_ce: 0.033112, loss_dice: 0.037992
iteration 291 : loss : 0.236786, loss_ce: 0.165716, loss_dice: 0.241951
iteration 292 : loss : 0.114070, loss_ce: 0.056390, loss_dice: 0.126803

  1%|▎                           | 21/2143 [14:42<22:57:21, 38.94s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 294 : loss : 0.120506, loss_ce: 0.076304, loss_dice: 0.113307
iteration 295 : loss : 0.085580, loss_ce: 0.063923, loss_dice: 0.046976
iteration 296 : loss : 0.107921, loss_ce: 0.064077, loss_dice: 0.110763
iteration 297 : loss : 0.180881, loss_ce: 0.046420, loss_dice: 0.266259
iteration 298 : loss : 0.126618, loss_ce: 0.104649, loss_dice: 0.070191
iteration 299 : loss : 0.110585, loss_ce: 0.114156, loss_dice: 0.067378
iteration 300 : loss : 0.125411, loss_ce: 0.107722, loss_dice: 0.095871
iteration 301 : loss : 0.138918, loss_ce: 0.087912, loss_dice: 0.146095
iteration 302 : loss : 0.115983, loss_ce: 0.095073, loss_dice: 0.076222
iteration 303 : loss : 0.099934, loss_ce: 0.068926, loss_dice: 0.085356
iteration 304 : loss : 0.125340, loss_ce: 0.118267, loss_dice: 0.074280
iteration 305 : loss : 0.206268, loss_ce: 0.134126, loss_dice: 0.217007
iteration 306 : loss : 0.109308, loss_ce: 0.094705, loss_dice: 0.070162

  1%|▎                           | 22/2143 [15:12<21:26:05, 36.38s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 308 : loss : 0.122125, loss_ce: 0.113652, loss_dice: 0.080610
iteration 309 : loss : 0.097997, loss_ce: 0.065684, loss_dice: 0.085610
iteration 310 : loss : 0.149558, loss_ce: 0.096733, loss_dice: 0.153595
iteration 311 : loss : 0.090514, loss_ce: 0.064938, loss_dice: 0.068913
iteration 312 : loss : 0.181359, loss_ce: 0.071993, loss_dice: 0.239022
iteration 313 : loss : 0.248869, loss_ce: 0.175635, loss_dice: 0.243890
iteration 314 : loss : 0.091077, loss_ce: 0.069884, loss_dice: 0.061845
iteration 315 : loss : 0.281837, loss_ce: 0.122419, loss_dice: 0.385223
iteration 316 : loss : 0.081767, loss_ce: 0.067947, loss_dice: 0.033864
iteration 317 : loss : 0.292296, loss_ce: 0.186020, loss_dice: 0.352423
iteration 318 : loss : 0.128018, loss_ce: 0.113058, loss_dice: 0.086352
iteration 319 : loss : 0.121802, loss_ce: 0.063147, loss_dice: 0.138358
iteration 320 : loss : 0.063249, loss_ce: 0.036055, loss_dice: 0.047405

  1%|▎                           | 23/2143 [15:43<20:23:31, 34.63s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 322 : loss : 0.076360, loss_ce: 0.049770, loss_dice: 0.046749
iteration 323 : loss : 0.233603, loss_ce: 0.169491, loss_dice: 0.228896
iteration 324 : loss : 0.148112, loss_ce: 0.111840, loss_dice: 0.132077
iteration 325 : loss : 0.098745, loss_ce: 0.078929, loss_dice: 0.078498
iteration 326 : loss : 0.068151, loss_ce: 0.046400, loss_dice: 0.046231
iteration 327 : loss : 0.170053, loss_ce: 0.127371, loss_dice: 0.142549
iteration 328 : loss : 0.091814, loss_ce: 0.066677, loss_dice: 0.065974
iteration 329 : loss : 0.074527, loss_ce: 0.050416, loss_dice: 0.028329
iteration 330 : loss : 0.114641, loss_ce: 0.086127, loss_dice: 0.108735
iteration 331 : loss : 0.094003, loss_ce: 0.081784, loss_dice: 0.066369
iteration 332 : loss : 0.164098, loss_ce: 0.135769, loss_dice: 0.139015
iteration 333 : loss : 0.216639, loss_ce: 0.118751, loss_dice: 0.273311
iteration 334 : loss : 0.108197, loss_ce: 0.044409, loss_dice: 0.125129

  1%|▎                           | 24/2143 [16:12<19:28:01, 33.07s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 336 : loss : 0.123124, loss_ce: 0.099400, loss_dice: 0.091248
iteration 337 : loss : 0.203870, loss_ce: 0.198885, loss_dice: 0.136967
iteration 338 : loss : 0.090319, loss_ce: 0.075354, loss_dice: 0.053861
iteration 339 : loss : 0.065176, loss_ce: 0.021138, loss_dice: 0.068242
iteration 340 : loss : 0.115190, loss_ce: 0.100947, loss_dice: 0.078880
iteration 341 : loss : 0.085962, loss_ce: 0.061485, loss_dice: 0.073737
iteration 342 : loss : 0.072468, loss_ce: 0.058414, loss_dice: 0.037444
iteration 343 : loss : 0.197493, loss_ce: 0.187603, loss_dice: 0.158662
iteration 344 : loss : 0.177584, loss_ce: 0.180051, loss_dice: 0.116105
iteration 345 : loss : 0.147893, loss_ce: 0.076246, loss_dice: 0.173514
iteration 346 : loss : 0.225829, loss_ce: 0.091464, loss_dice: 0.306118
iteration 347 : loss : 0.192502, loss_ce: 0.112252, loss_dice: 0.217774

  1%|▎                           | 25/2143 [16:41<18:47:33, 31.94s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 349 : loss : 0.159734, loss_ce: 0.083375, loss_dice: 0.184615
iteration 350 : loss : 0.079322, loss_ce: 0.062405, loss_dice: 0.053634
iteration 351 : loss : 0.130606, loss_ce: 0.094895, loss_dice: 0.112636
iteration 352 : loss : 0.372206, loss_ce: 0.273813, loss_dice: 0.423076
iteration 353 : loss : 0.147649, loss_ce: 0.103206, loss_dice: 0.138631
iteration 354 : loss : 0.147607, loss_ce: 0.044259, loss_dice: 0.194557
iteration 355 : loss : 0.120164, loss_ce: 0.103800, loss_dice: 0.084876
iteration 356 : loss : 0.246239, loss_ce: 0.240303, loss_dice: 0.174279
iteration 357 : loss : 0.101555, loss_ce: 0.099217, loss_dice: 0.053740
iteration 358 : loss : 0.175287, loss_ce: 0.149736, loss_dice: 0.142247
iteration 359 : loss : 0.168897, loss_ce: 0.114839, loss_dice: 0.179073
iteration 360 : loss : 0.353932, loss_ce: 0.183399, loss_dice: 0.475255
iteration 361 : loss : 0.133868, loss_ce: 0.112867, loss_dice: 0.106137
iteration 362 : loss : 0.183988, loss_ce: 0.073942, loss_dice: 0.241128

  1%|▎                           | 26/2143 [17:11<18:21:03, 31.21s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 364 : loss : 0.163454, loss_ce: 0.115883, loss_dice: 0.171301
iteration 365 : loss : 0.099392, loss_ce: 0.033623, loss_dice: 0.114067
iteration 366 : loss : 0.109341, loss_ce: 0.070870, loss_dice: 0.099328
iteration 367 : loss : 0.083577, loss_ce: 0.063640, loss_dice: 0.047284
iteration 368 : loss : 0.100489, loss_ce: 0.066593, loss_dice: 0.083812
iteration 369 : loss : 0.203724, loss_ce: 0.154641, loss_dice: 0.209644
iteration 370 : loss : 0.122843, loss_ce: 0.064731, loss_dice: 0.124957
iteration 371 : loss : 0.252701, loss_ce: 0.154237, loss_dice: 0.282493
iteration 372 : loss : 0.242668, loss_ce: 0.246792, loss_dice: 0.179566
iteration 373 : loss : 0.079412, loss_ce: 0.058931, loss_dice: 0.051059
iteration 374 : loss : 0.171359, loss_ce: 0.161747, loss_dice: 0.115529
iteration 375 : loss : 0.313352, loss_ce: 0.304158, loss_dice: 0.267112
iteration 376 : loss : 0.119838, loss_ce: 0.076101, loss_dice: 0.110752

  1%|▎                           | 27/2143 [17:40<18:03:52, 30.73s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 378 : loss : 0.105042, loss_ce: 0.083865, loss_dice: 0.049647
iteration 379 : loss : 0.164880, loss_ce: 0.033487, loss_dice: 0.252474
iteration 380 : loss : 0.139449, loss_ce: 0.127162, loss_dice: 0.095203
iteration 381 : loss : 0.075938, loss_ce: 0.060288, loss_dice: 0.046159
iteration 382 : loss : 0.110006, loss_ce: 0.109309, loss_dice: 0.067963
iteration 383 : loss : 0.096875, loss_ce: 0.099055, loss_dice: 0.055029
iteration 384 : loss : 0.100183, loss_ce: 0.062648, loss_dice: 0.094053
iteration 385 : loss : 0.142312, loss_ce: 0.111753, loss_dice: 0.125796
iteration 386 : loss : 0.289003, loss_ce: 0.128465, loss_dice: 0.396022
iteration 387 : loss : 0.090952, loss_ce: 0.053136, loss_dice: 0.074859
iteration 388 : loss : 0.118046, loss_ce: 0.103739, loss_dice: 0.073725
iteration 389 : loss : 0.182680, loss_ce: 0.191168, loss_dice: 0.113041
iteration 390 : loss : 0.199949, loss_ce: 0.199983, loss_dice: 0.140532

  1%|▎                           | 28/2143 [18:10<17:52:45, 30.43s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [04:08<00:00,  3.21s/it]
iteration 392 : loss : 0.138761, loss_ce: 0.130964, loss_dice: 0.110413
iteration 393 : loss : 0.148503, loss_ce: 0.119376, loss_dice: 0.130516
iteration 394 : loss : 0.104846, loss_ce: 0.086019, loss_dice: 0.069083
iteration 395 : loss : 0.138154, loss_ce: 0.058069, loss_dice: 0.173494
iteration 396 : loss : 0.102071, loss_ce: 0.062658, loss_dice: 0.090565
iteration 397 : loss : 0.251042, loss_ce: 0.235317, loss_dice: 0.211683
iteration 398 : loss : 0.072445, loss_ce: 0.068585, loss_dice: 0.032583
iteration 399 : loss : 0.134124, loss_ce: 0.094142, loss_dice: 0.122639
  0%|                                                                                                                                                                                                            | 0/67 [00:00<?, ?it/s]
iteration 400 : loss : 0.157752, loss_ce: 0.140997, loss_dice: 0.127771


































































 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 66/67 [03:56<00:03,  3.12s/it]
Validation end

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [03:59<00:00,  3.13s/it]
iteration 401 : loss : 0.239905, loss_ce: 0.184184, loss_dice: 0.230256
iteration 402 : loss : 0.095847, loss_ce: 0.072210, loss_dice: 0.068167
iteration 403 : loss : 0.116612, loss_ce: 0.095317, loss_dice: 0.090933
iteration 404 : loss : 0.091986, loss_ce: 0.077435, loss_dice: 0.067635
iteration 405 : loss : 0.056199, loss_ce: 0.033796, loss_dice: 0.037862

  1%|▎                          | 29/2143 [22:40<59:57:11, 102.10s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [03:59<00:00,  3.13s/it]
iteration 407 : loss : 0.192153, loss_ce: 0.182496, loss_dice: 0.148204
iteration 408 : loss : 0.193370, loss_ce: 0.164345, loss_dice: 0.178593
iteration 409 : loss : 0.309488, loss_ce: 0.201855, loss_dice: 0.306715
iteration 410 : loss : 0.084965, loss_ce: 0.069818, loss_dice: 0.062869
iteration 411 : loss : 0.145311, loss_ce: 0.152062, loss_dice: 0.084228
iteration 412 : loss : 0.128083, loss_ce: 0.106832, loss_dice: 0.103021
iteration 413 : loss : 0.144138, loss_ce: 0.087352, loss_dice: 0.157047
iteration 414 : loss : 0.097947, loss_ce: 0.088810, loss_dice: 0.064947
  1%|▍                           | 29/2143 [23:00<27:57:03, 47.60s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [03:59<00:00,  3.13s/it]
Traceback (most recent call last):
  File "Brats2_GDT_MT_kfold.py", line 329, in <module>
    train(args, snapshot_path)
  File "Brats2_GDT_MT_kfold.py", line 205, in train
    loss_dice = dice_loss(outputs_soft_2class[:labeled_bs], label_batch[:labeled_bs].unsqueeze(1).float())
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/sohui/code/SSL_brats/code/utils/losses.py", line 196, in forward
    class_wise_dice.append(1.0 - dice.item())
KeyboardInterrupt