
Namespace(D_lr=0.0001, base_lr=0.01, batch_size=4, beta=0.3, consistency=1.0, consistency_rampup=40.0, consistency_type='kl', consistency_weight=0.1, deterministic=1, ema_decay=0.99, exp='test', gamma=0.5, gpu='4', labeled_bs=2, labelnum=16, max_iterations=6000, model='test', root_path='/data/sohui/LA_dataset/2018LA_Seg_TrainingSet', seed=1337, total_labeled_num=80, with_cons='without_cons')
total 80 samples
8 itertations per epoch
  0%|                                         | 0/751 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/home/sohui/.pycharm_helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/sohui/.pycharm_helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/sohui/code/SSL_brats/DTC/code/LA_train_dtc.py", line 191, in <module>
    loss_seg = ce_loss(
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 714, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/torch/nn/functional.py", line 2829, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 3.19 GiB already allocated; 13.94 MiB free; 3.21 GiB reserved in total by PyTorch)