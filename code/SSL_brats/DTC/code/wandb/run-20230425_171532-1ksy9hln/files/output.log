
Namespace(D_lr=0.0001, base_lr=0.01, batch_size=4, beta=0.3, consistency=1.0, consistency_rampup=40.0, consistency_type='kl', consistency_weight=0.1, deterministic=1, ema_decay=0.99, exp='DTC_kfold', fold=2, gamma=0.5, gpu='4', labeled_bs=2, labelnum=56, max_iterations=30000, model='vnet_3D_96_32', root_path='/data/sohui/BraTS/data/BraTs2019', seed=1337, total_data_num=268, with_cons='without_cons')
total 268 samples
28 itertations per epoch
  0%|                                        | 0/1072 [00:00<?, ?it/s]
iteration 1 : loss : 0.954910, loss_consis: 0.250083, loss_haus: 0.152443, loss_seg: 0.711404, loss_dice: 0.907492
iteration 1 : loss : 0.954910
iteration 2 : loss : 0.950807, loss_consis: 0.225667, loss_haus: 0.302494, loss_seg: 0.685335, loss_dice: 0.858539
iteration 2 : loss : 0.950807
iteration 3 : loss : 0.783840, loss_consis: 0.201989, loss_haus: 0.135614, loss_seg: 0.587124, loss_dice: 0.741795
iteration 3 : loss : 0.783840
iteration 4 : loss : 0.645223, loss_consis: 0.211737, loss_haus: 0.205087, loss_seg: 0.607980, loss_dice: 0.582271
iteration 4 : loss : 0.645223
iteration 5 : loss : 0.981786, loss_consis: 0.233936, loss_haus: 0.144778, loss_seg: 0.662752, loss_dice: 0.936776
iteration 5 : loss : 0.981786
iteration 6 : loss : 0.612563, loss_consis: 0.202975, loss_haus: 0.128282, loss_seg: 0.687583, loss_dice: 0.572711
iteration 6 : loss : 0.612563
iteration 7 : loss : 0.961799, loss_consis: 0.216683, loss_haus: 0.329146, loss_seg: 0.726672, loss_dice: 0.861595
iteration 7 : loss : 0.961799
iteration 8 : loss : 0.706233, loss_consis: 0.206654, loss_haus: 0.154551, loss_seg: 0.627559, loss_dice: 0.658475
iteration 8 : loss : 0.706233
iteration 9 : loss : 0.886615, loss_consis: 0.196639, loss_haus: 0.108445, loss_seg: 0.614353, loss_dice: 0.852756
iteration 9 : loss : 0.886615
iteration 10 : loss : 0.582499, loss_consis: 0.177791, loss_haus: 0.123275, loss_seg: 0.522666, loss_dice: 0.544318
iteration 10 : loss : 0.582499
iteration 11 : loss : 0.878232, loss_consis: 0.193877, loss_haus: 0.096892, loss_seg: 0.632600, loss_dice: 0.847858
iteration 11 : loss : 0.878232
iteration 12 : loss : 0.577134, loss_consis: 0.190310, loss_haus: 0.133669, loss_seg: 0.532672, loss_dice: 0.535752
iteration 12 : loss : 0.577134
iteration 13 : loss : 0.772742, loss_consis: 0.200926, loss_haus: 0.122276, loss_seg: 0.602438, loss_dice: 0.734706
iteration 13 : loss : 0.772742
iteration 14 : loss : 0.784295, loss_consis: 0.163209, loss_haus: 0.130903, loss_seg: 0.469360, loss_dice: 0.743925
iteration 14 : loss : 0.784295
iteration 15 : loss : 0.934680, loss_consis: 0.177123, loss_haus: 0.073145, loss_seg: 0.535844, loss_dice: 0.911543
iteration 15 : loss : 0.934680
iteration 16 : loss : 0.729096, loss_consis: 0.182316, loss_haus: 0.076679, loss_seg: 0.520981, loss_dice: 0.704864
iteration 16 : loss : 0.729096
iteration 17 : loss : 0.744953, loss_consis: 0.185659, loss_haus: 0.130306, loss_seg: 0.559374, loss_dice: 0.704610
iteration 17 : loss : 0.744953
iteration 18 : loss : 0.626717, loss_consis: 0.160920, loss_haus: 0.061991, loss_seg: 0.476821, loss_dice: 0.607035
iteration 18 : loss : 0.626717
iteration 19 : loss : 0.902946, loss_consis: 0.166476, loss_haus: 0.088082, loss_seg: 0.493993, loss_dice: 0.875400
iteration 19 : loss : 0.902946
iteration 20 : loss : 0.765028, loss_consis: 0.119019, loss_haus: 0.078609, loss_seg: 0.434026, loss_dice: 0.740644
iteration 20 : loss : 0.765028
iteration 21 : loss : 0.473923, loss_consis: 0.164358, loss_haus: 0.089012, loss_seg: 0.447050, loss_dice: 0.446112
iteration 21 : loss : 0.473923
iteration 22 : loss : 0.732716, loss_consis: 0.120582, loss_haus: 0.076870, loss_seg: 0.430071, loss_dice: 0.708842
iteration 22 : loss : 0.732716
iteration 23 : loss : 0.608136, loss_consis: 0.161198, loss_haus: 0.102128, loss_seg: 0.440499, loss_dice: 0.576412
iteration 23 : loss : 0.608136
iteration 24 : loss : 0.810248, loss_consis: 0.148285, loss_haus: 0.072434, loss_seg: 0.428487, loss_dice: 0.787519
iteration 24 : loss : 0.810248
iteration 25 : loss : 0.693275, loss_consis: 0.152828, loss_haus: 0.088578, loss_seg: 0.476409, loss_dice: 0.665671
iteration 25 : loss : 0.693275
iteration 26 : loss : 0.698555, loss_consis: 0.115061, loss_haus: 0.152613, loss_seg: 0.409336, loss_dice: 0.651996
iteration 26 : loss : 0.698555
iteration 27 : loss : 0.333347, loss_consis: 0.134537, loss_haus: 0.141916, loss_seg: 0.374565, loss_dice: 0.289866

  0%|                             | 1/1072 [00:44<13:17:54, 44.70s/it]
iteration 28 : loss : 0.355815, loss_consis: 0.111891, loss_haus: 0.133790, loss_seg: 0.357473, loss_dice: 0.314924
iteration 28 : loss : 0.355815
iteration 29 : loss : 0.589407, loss_consis: 0.109434, loss_haus: 0.069563, loss_seg: 0.378971, loss_dice: 0.567801
iteration 29 : loss : 0.589407
iteration 30 : loss : 0.449816, loss_consis: 0.122687, loss_haus: 0.093500, loss_seg: 0.325843, loss_dice: 0.420939
iteration 30 : loss : 0.449816
iteration 31 : loss : 0.620904, loss_consis: 0.119297, loss_haus: 0.070053, loss_seg: 0.382840, loss_dice: 0.599084
iteration 31 : loss : 0.620904
iteration 32 : loss : 0.488801, loss_consis: 0.101159, loss_haus: 0.063045, loss_seg: 0.381160, loss_dice: 0.469206
iteration 32 : loss : 0.488801
iteration 33 : loss : 0.588365, loss_consis: 0.124807, loss_haus: 0.131180, loss_seg: 0.447071, loss_dice: 0.548170
iteration 33 : loss : 0.588365
iteration 34 : loss : 0.466889, loss_consis: 0.107609, loss_haus: 0.100590, loss_seg: 0.368367, loss_dice: 0.435987
iteration 34 : loss : 0.466889
iteration 35 : loss : 0.384554, loss_consis: 0.085459, loss_haus: 0.068633, loss_seg: 0.300209, loss_dice: 0.363388
iteration 35 : loss : 0.384554
iteration 36 : loss : 0.427896, loss_consis: 0.090650, loss_haus: 0.104212, loss_seg: 0.335535, loss_dice: 0.396022
iteration 36 : loss : 0.427896
iteration 37 : loss : 0.976135, loss_consis: 0.089496, loss_haus: 0.060905, loss_seg: 0.339856, loss_dice: 0.957261
iteration 37 : loss : 0.976135
iteration 38 : loss : 0.455087, loss_consis: 0.091478, loss_haus: 0.071276, loss_seg: 0.348765, loss_dice: 0.433088
iteration 38 : loss : 0.455087
iteration 39 : loss : 0.440894, loss_consis: 0.068916, loss_haus: 0.054702, loss_seg: 0.305270, loss_dice: 0.424019
iteration 39 : loss : 0.440894
iteration 40 : loss : 0.395090, loss_consis: 0.067153, loss_haus: 0.057568, loss_seg: 0.291233, loss_dice: 0.377367
iteration 40 : loss : 0.395090
iteration 41 : loss : 0.573124, loss_consis: 0.067919, loss_haus: 0.060284, loss_seg: 0.329620, loss_dice: 0.554581
iteration 41 : loss : 0.573124
iteration 42 : loss : 0.309541, loss_consis: 0.056010, loss_haus: 0.056495, loss_seg: 0.294193, loss_dice: 0.292215
iteration 42 : loss : 0.309541
iteration 43 : loss : 0.307886, loss_consis: 0.054541, loss_haus: 0.075665, loss_seg: 0.280221, loss_dice: 0.284819
iteration 43 : loss : 0.307886
iteration 44 : loss : 0.247180, loss_consis: 0.065967, loss_haus: 0.110932, loss_seg: 0.218972, loss_dice: 0.213456
iteration 44 : loss : 0.247180
iteration 45 : loss : 0.327879, loss_consis: 0.066950, loss_haus: 0.055900, loss_seg: 0.256498, loss_dice: 0.310658
iteration 45 : loss : 0.327879
iteration 46 : loss : 0.373345, loss_consis: 0.082978, loss_haus: 0.055143, loss_seg: 0.212700, loss_dice: 0.356242
iteration 46 : loss : 0.373345
iteration 47 : loss : 0.482817, loss_consis: 0.043529, loss_haus: 0.063399, loss_seg: 0.225917, loss_dice: 0.463504
iteration 47 : loss : 0.482817
iteration 48 : loss : 0.694842, loss_consis: 0.054233, loss_haus: 0.071865, loss_seg: 0.267713, loss_dice: 0.672917
iteration 48 : loss : 0.694842
iteration 49 : loss : 0.631674, loss_consis: 0.055485, loss_haus: 0.082797, loss_seg: 0.395398, loss_dice: 0.606461
iteration 49 : loss : 0.631674
iteration 50 : loss : 0.167034, loss_consis: 0.068201, loss_haus: 0.060940, loss_seg: 0.144183, loss_dice: 0.148293
iteration 50 : loss : 0.167034
iteration 51 : loss : 0.693543, loss_consis: 0.045502, loss_haus: 0.088594, loss_seg: 0.266811, loss_dice: 0.666658
iteration 51 : loss : 0.693543
iteration 52 : loss : 0.593758, loss_consis: 0.050954, loss_haus: 0.058713, loss_seg: 0.333656, loss_dice: 0.575800
iteration 52 : loss : 0.593758
iteration 53 : loss : 0.362649, loss_consis: 0.049885, loss_haus: 0.071780, loss_seg: 0.205141, loss_dice: 0.340778
iteration 53 : loss : 0.362649
iteration 54 : loss : 0.261569, loss_consis: 0.046592, loss_haus: 0.043812, loss_seg: 0.137364, loss_dice: 0.248112
iteration 54 : loss : 0.261569
iteration 55 : loss : 0.562175, loss_consis: 0.030804, loss_haus: 0.076050, loss_seg: 0.134758, loss_dice: 0.539153

  0%|                             | 2/1072 [01:29<13:22:24, 45.00s/it]
iteration 56 : loss : 0.113176, loss_consis: 0.028623, loss_haus: 0.053663, loss_seg: 0.144295, loss_dice: 0.096884
iteration 56 : loss : 0.113176
iteration 57 : loss : 0.324875, loss_consis: 0.040153, loss_haus: 0.060715, loss_seg: 0.138964, loss_dice: 0.306390
iteration 57 : loss : 0.324875
iteration 58 : loss : 0.367480, loss_consis: 0.038820, loss_haus: 0.080782, loss_seg: 0.227882, loss_dice: 0.342984
iteration 58 : loss : 0.367480
iteration 59 : loss : 0.490203, loss_consis: 0.026300, loss_haus: 0.071791, loss_seg: 0.200780, loss_dice: 0.468489
iteration 59 : loss : 0.490203
iteration 60 : loss : 0.607704, loss_consis: 0.034411, loss_haus: 0.075177, loss_seg: 0.257423, loss_dice: 0.584919
iteration 60 : loss : 0.607704
iteration 61 : loss : 0.486454, loss_consis: 0.042972, loss_haus: 0.088263, loss_seg: 0.176629, loss_dice: 0.459686
iteration 61 : loss : 0.486454
iteration 62 : loss : 0.301332, loss_consis: 0.021155, loss_haus: 0.050959, loss_seg: 0.167933, loss_dice: 0.285902
iteration 62 : loss : 0.301332
iteration 63 : loss : 0.354389, loss_consis: 0.032269, loss_haus: 0.069257, loss_seg: 0.220382, loss_dice: 0.333394
iteration 63 : loss : 0.354389
iteration 64 : loss : 0.397823, loss_consis: 0.015323, loss_haus: 0.083194, loss_seg: 0.140144, loss_dice: 0.372762
iteration 64 : loss : 0.397823
iteration 65 : loss : 0.237922, loss_consis: 0.017808, loss_haus: 0.043129, loss_seg: 0.116559, loss_dice: 0.224864
iteration 65 : loss : 0.237922
iteration 66 : loss : 0.288727, loss_consis: 0.032070, loss_haus: 0.122707, loss_seg: 0.275769, loss_dice: 0.251698
iteration 66 : loss : 0.288727
iteration 67 : loss : 0.460191, loss_consis: 0.024168, loss_haus: 0.073194, loss_seg: 0.195621, loss_dice: 0.438070
iteration 67 : loss : 0.460191
iteration 68 : loss : 0.194863, loss_consis: 0.015495, loss_haus: 0.043732, loss_seg: 0.126163, loss_dice: 0.181639
iteration 68 : loss : 0.194863
iteration 69 : loss : 0.792221, loss_consis: 0.032112, loss_haus: 0.118439, loss_seg: 0.138421, loss_dice: 0.756473
iteration 69 : loss : 0.792221
iteration 70 : loss : 0.543108, loss_consis: 0.015432, loss_haus: 0.078229, loss_seg: 0.211154, loss_dice: 0.519535
iteration 70 : loss : 0.543108
iteration 71 : loss : 0.281850, loss_consis: 0.024026, loss_haus: 0.052187, loss_seg: 0.110992, loss_dice: 0.266032
iteration 71 : loss : 0.281850
iteration 72 : loss : 0.174612, loss_consis: 0.019569, loss_haus: 0.068988, loss_seg: 0.158135, loss_dice: 0.153784
iteration 72 : loss : 0.174612
iteration 73 : loss : 0.115801, loss_consis: 0.011576, loss_haus: 0.063373, loss_seg: 0.113148, loss_dice: 0.096711
iteration 73 : loss : 0.115801
iteration 74 : loss : 0.277735, loss_consis: 0.014910, loss_haus: 0.042310, loss_seg: 0.120331, loss_dice: 0.264942
iteration 74 : loss : 0.277735
iteration 75 : loss : 0.254381, loss_consis: 0.012106, loss_haus: 0.053796, loss_seg: 0.107817, loss_dice: 0.238161
iteration 75 : loss : 0.254381
iteration 76 : loss : 0.531766, loss_consis: 0.032283, loss_haus: 0.048553, loss_seg: 0.160884, loss_dice: 0.516982
iteration 76 : loss : 0.531766
iteration 77 : loss : 0.392545, loss_consis: 0.023358, loss_haus: 0.089607, loss_seg: 0.219425, loss_dice: 0.365506
iteration 77 : loss : 0.392545
iteration 78 : loss : 0.533325, loss_consis: 0.036063, loss_haus: 0.051086, loss_seg: 0.181999, loss_dice: 0.517756
iteration 78 : loss : 0.533325
iteration 79 : loss : 0.150018, loss_consis: 0.018350, loss_haus: 0.054078, loss_seg: 0.126736, loss_dice: 0.133671
iteration 79 : loss : 0.150018
iteration 80 : loss : 0.340707, loss_consis: 0.024572, loss_haus: 0.048399, loss_seg: 0.169085, loss_dice: 0.326022
iteration 80 : loss : 0.340707
iteration 81 : loss : 0.217133, loss_consis: 0.019089, loss_haus: 0.044531, loss_seg: 0.143143, loss_dice: 0.203645
iteration 81 : loss : 0.217133
iteration 82 : loss : 0.175305, loss_consis: 0.030258, loss_haus: 0.072028, loss_seg: 0.163397, loss_dice: 0.153493

  0%|                             | 3/1072 [02:09<12:37:34, 42.52s/it]
iteration 83 : loss : 0.177565, loss_consis: 0.018438, loss_haus: 0.066964, loss_seg: 0.070391, loss_dice: 0.157351
iteration 83 : loss : 0.177565
iteration 84 : loss : 0.300284, loss_consis: 0.019349, loss_haus: 0.081411, loss_seg: 0.160851, loss_dice: 0.275730
iteration 84 : loss : 0.300284
iteration 85 : loss : 0.381625, loss_consis: 0.028150, loss_haus: 0.059257, loss_seg: 0.257649, loss_dice: 0.363659
iteration 85 : loss : 0.381625
iteration 86 : loss : 0.616689, loss_consis: 0.031112, loss_haus: 0.071480, loss_seg: 0.196686, loss_dice: 0.595036
iteration 86 : loss : 0.616689
iteration 87 : loss : 0.322716, loss_consis: 0.020980, loss_haus: 0.061491, loss_seg: 0.184616, loss_dice: 0.304127
iteration 87 : loss : 0.322716
iteration 88 : loss : 0.234345, loss_consis: 0.016256, loss_haus: 0.049684, loss_seg: 0.127313, loss_dice: 0.219331
iteration 88 : loss : 0.234345
iteration 89 : loss : 0.126887, loss_consis: 0.017603, loss_haus: 0.084883, loss_seg: 0.092414, loss_dice: 0.101304
iteration 89 : loss : 0.126887
iteration 90 : loss : 0.272228, loss_consis: 0.022438, loss_haus: 0.065652, loss_seg: 0.167011, loss_dice: 0.252381
iteration 90 : loss : 0.272228
iteration 91 : loss : 0.305818, loss_consis: 0.027766, loss_haus: 0.052498, loss_seg: 0.087491, loss_dice: 0.289882
iteration 91 : loss : 0.305818
iteration 92 : loss : 0.310935, loss_consis: 0.019149, loss_haus: 0.087387, loss_seg: 0.087760, loss_dice: 0.284590
iteration 92 : loss : 0.310935
iteration 93 : loss : 0.135582, loss_consis: 0.012427, loss_haus: 0.054239, loss_seg: 0.096316, loss_dice: 0.119227
iteration 93 : loss : 0.135582
iteration 94 : loss : 0.226482, loss_consis: 0.023420, loss_haus: 0.059059, loss_seg: 0.141570, loss_dice: 0.208606
iteration 94 : loss : 0.226482
iteration 95 : loss : 0.288872, loss_consis: 0.025928, loss_haus: 0.041389, loss_seg: 0.149804, loss_dice: 0.276281
iteration 95 : loss : 0.288872
iteration 96 : loss : 0.492985, loss_consis: 0.014945, loss_haus: 0.066824, loss_seg: 0.172080, loss_dice: 0.472837
iteration 96 : loss : 0.492985
iteration 97 : loss : 0.249938, loss_consis: 0.021941, loss_haus: 0.048364, loss_seg: 0.142326, loss_dice: 0.235280
iteration 97 : loss : 0.249938
iteration 98 : loss : 0.219518, loss_consis: 0.015310, loss_haus: 0.054598, loss_seg: 0.076112, loss_dice: 0.203035
iteration 98 : loss : 0.219518
iteration 99 : loss : 0.208041, loss_consis: 0.017516, loss_haus: 0.055931, loss_seg: 0.127546, loss_dice: 0.191143
iteration 99 : loss : 0.208041
iteration 100 : loss : 0.560268, loss_consis: 0.018091, loss_haus: 0.087838, loss_seg: 0.302658, loss_dice: 0.533795
iteration 100 : loss : 0.560268
iteration 101 : loss : 0.508239, loss_consis: 0.022409, loss_haus: 0.078827, loss_seg: 0.262310, loss_dice: 0.484440
iteration 101 : loss : 0.508239
iteration 102 : loss : 0.278711, loss_consis: 0.015474, loss_haus: 0.040950, loss_seg: 0.073569, loss_dice: 0.266322
iteration 102 : loss : 0.278711
iteration 103 : loss : 0.510029, loss_consis: 0.013060, loss_haus: 0.052794, loss_seg: 0.114675, loss_dice: 0.494103
iteration 103 : loss : 0.510029
iteration 104 : loss : 0.172904, loss_consis: 0.022996, loss_haus: 0.050502, loss_seg: 0.114399, loss_dice: 0.157598
iteration 104 : loss : 0.172904
iteration 105 : loss : 0.103979, loss_consis: 0.014761, loss_haus: 0.043242, loss_seg: 0.045073, loss_dice: 0.090906
iteration 105 : loss : 0.103979
iteration 106 : loss : 0.217615, loss_consis: 0.025308, loss_haus: 0.059311, loss_seg: 0.186947, loss_dice: 0.199651
iteration 106 : loss : 0.217615
iteration 107 : loss : 0.415794, loss_consis: 0.020653, loss_haus: 0.064853, loss_seg: 0.144632, loss_dice: 0.396199
iteration 107 : loss : 0.415794
iteration 108 : loss : 0.312326, loss_consis: 0.011736, loss_haus: 0.060755, loss_seg: 0.111499, loss_dice: 0.294021
iteration 108 : loss : 0.312326
iteration 109 : loss : 0.151377, loss_consis: 0.014841, loss_haus: 0.049478, loss_seg: 0.104493, loss_dice: 0.136433
iteration 109 : loss : 0.151377
iteration 110 : loss : 0.126115, loss_consis: 0.012395, loss_haus: 0.049927, loss_seg: 0.090230, loss_dice: 0.111053
iteration 110 : loss : 0.126115
iteration 111 : loss : 0.345838, loss_consis: 0.018759, loss_haus: 0.045650, loss_seg: 0.091889, loss_dice: 0.332016
iteration 111 : loss : 0.345838
iteration 112 : loss : 0.121407, loss_consis: 0.012194, loss_haus: 0.055516, loss_seg: 0.092477, loss_dice: 0.104670

  0%|                             | 4/1072 [02:47<12:08:04, 40.90s/it]
iteration 113 : loss : 0.293115, loss_consis: 0.021304, loss_haus: 0.069465, loss_seg: 0.139510, loss_dice: 0.272132
iteration 113 : loss : 0.293115
iteration 114 : loss : 0.187333, loss_consis: 0.013932, loss_haus: 0.041097, loss_seg: 0.083892, loss_dice: 0.174911
iteration 114 : loss : 0.187333
iteration 115 : loss : 0.399646, loss_consis: 0.018910, loss_haus: 0.044068, loss_seg: 0.134836, loss_dice: 0.386298
iteration 115 : loss : 0.399646
iteration 116 : loss : 0.130486, loss_consis: 0.012261, loss_haus: 0.040960, loss_seg: 0.083070, loss_dice: 0.118115
iteration 116 : loss : 0.130486
iteration 117 : loss : 0.155179, loss_consis: 0.010920, loss_haus: 0.048310, loss_seg: 0.095365, loss_dice: 0.140613
iteration 117 : loss : 0.155179
iteration 118 : loss : 0.378832, loss_consis: 0.012196, loss_haus: 0.064476, loss_seg: 0.199875, loss_dice: 0.359407
iteration 118 : loss : 0.378832
iteration 119 : loss : 0.235912, loss_consis: 0.007502, loss_haus: 0.049187, loss_seg: 0.062793, loss_dice: 0.221105
iteration 119 : loss : 0.235912
iteration 120 : loss : 0.207505, loss_consis: 0.017683, loss_haus: 0.047774, loss_seg: 0.084131, loss_dice: 0.193054
iteration 120 : loss : 0.207505
iteration 121 : loss : 0.405304, loss_consis: 0.011944, loss_haus: 0.065036, loss_seg: 0.107820, loss_dice: 0.385713
iteration 121 : loss : 0.405304
iteration 122 : loss : 0.530733, loss_consis: 0.008222, loss_haus: 0.076571, loss_seg: 0.342885, loss_dice: 0.507707
iteration 122 : loss : 0.530733
iteration 123 : loss : 0.287893, loss_consis: 0.011231, loss_haus: 0.042891, loss_seg: 0.103955, loss_dice: 0.274950
iteration 123 : loss : 0.287893
iteration 124 : loss : 0.473046, loss_consis: 0.012748, loss_haus: 0.066898, loss_seg: 0.231078, loss_dice: 0.452890
iteration 124 : loss : 0.473046
iteration 125 : loss : 0.806485, loss_consis: 0.011842, loss_haus: 0.076310, loss_seg: 0.159389, loss_dice: 0.783512
iteration 125 : loss : 0.806485
iteration 126 : loss : 0.276754, loss_consis: 0.010132, loss_haus: 0.052402, loss_seg: 0.122089, loss_dice: 0.260965
iteration 126 : loss : 0.276754
iteration 127 : loss : 0.140714, loss_consis: 0.012011, loss_haus: 0.046309, loss_seg: 0.118619, loss_dice: 0.126741
iteration 127 : loss : 0.140714
iteration 128 : loss : 0.171130, loss_consis: 0.007764, loss_haus: 0.050094, loss_seg: 0.064946, loss_dice: 0.156049
iteration 128 : loss : 0.171130
iteration 129 : loss : 0.584508, loss_consis: 0.017049, loss_haus: 0.066538, loss_seg: 0.168070, loss_dice: 0.564431
iteration 129 : loss : 0.584508
iteration 130 : loss : 0.067980, loss_consis: 0.007395, loss_haus: 0.041171, loss_seg: 0.066179, loss_dice: 0.055579
iteration 130 : loss : 0.067980
iteration 131 : loss : 0.411769, loss_consis: 0.006292, loss_haus: 0.050810, loss_seg: 0.155284, loss_dice: 0.396484
iteration 131 : loss : 0.411769
iteration 132 : loss : 0.349279, loss_consis: 0.010939, loss_haus: 0.066598, loss_seg: 0.243694, loss_dice: 0.329225
iteration 132 : loss : 0.349279
iteration 133 : loss : 0.391691, loss_consis: 0.014686, loss_haus: 0.045281, loss_seg: 0.106846, loss_dice: 0.378008
iteration 133 : loss : 0.391691
iteration 134 : loss : 0.458081, loss_consis: 0.019211, loss_haus: 0.050676, loss_seg: 0.111770, loss_dice: 0.442749
iteration 134 : loss : 0.458081
iteration 135 : loss : 0.380423, loss_consis: 0.022981, loss_haus: 0.063877, loss_seg: 0.194022, loss_dice: 0.361105
iteration 135 : loss : 0.380423
iteration 136 : loss : 0.184028, loss_consis: 0.012518, loss_haus: 0.047690, loss_seg: 0.074573, loss_dice: 0.169636
iteration 136 : loss : 0.184028
iteration 137 : loss : 0.195945, loss_consis: 0.020361, loss_haus: 0.046578, loss_seg: 0.086237, loss_dice: 0.181834
iteration 137 : loss : 0.195945
iteration 138 : loss : 0.271244, loss_consis: 0.021954, loss_haus: 0.067490, loss_seg: 0.219731, loss_dice: 0.250849
iteration 138 : loss : 0.271244
iteration 139 : loss : 0.109266, loss_consis: 0.012902, loss_haus: 0.044964, loss_seg: 0.071511, loss_dice: 0.095690
iteration 139 : loss : 0.109266
iteration 140 : loss : 0.237505, loss_consis: 0.012930, loss_haus: 0.058654, loss_seg: 0.080968, loss_dice: 0.219822

  0%|▏                            | 5/1072 [03:25<11:48:09, 39.82s/it]
iteration 141 : loss : 0.400338, loss_consis: 0.011708, loss_haus: 0.061589, loss_seg: 0.160506, loss_dice: 0.381783
iteration 141 : loss : 0.400338
iteration 142 : loss : 0.201632, loss_consis: 0.016539, loss_haus: 0.063567, loss_seg: 0.100488, loss_dice: 0.182451
iteration 142 : loss : 0.201632
iteration 143 : loss : 0.194476, loss_consis: 0.016003, loss_haus: 0.036397, loss_seg: 0.084373, loss_dice: 0.183449
iteration 143 : loss : 0.194476
iteration 144 : loss : 0.218612, loss_consis: 0.022830, loss_haus: 0.050367, loss_seg: 0.114167, loss_dice: 0.203348
iteration 144 : loss : 0.218612
iteration 145 : loss : 0.602606, loss_consis: 0.025477, loss_haus: 0.113468, loss_seg: 0.240944, loss_dice: 0.568394
iteration 145 : loss : 0.602606
iteration 146 : loss : 0.090579, loss_consis: 0.018223, loss_haus: 0.042951, loss_seg: 0.064634, loss_dice: 0.077570
iteration 146 : loss : 0.090579
iteration 147 : loss : 0.252298, loss_consis: 0.022060, loss_haus: 0.050837, loss_seg: 0.120126, loss_dice: 0.236899
iteration 147 : loss : 0.252298
iteration 148 : loss : 0.521562, loss_consis: 0.031602, loss_haus: 0.047014, loss_seg: 0.263795, loss_dice: 0.507244
iteration 148 : loss : 0.521562
iteration 149 : loss : 0.205420, loss_consis: 0.032341, loss_haus: 0.044020, loss_seg: 0.059277, loss_dice: 0.191996
iteration 149 : loss : 0.205420
iteration 150 : loss : 0.213707, loss_consis: 0.025935, loss_haus: 0.048418, loss_seg: 0.096063, loss_dice: 0.199007
iteration 150 : loss : 0.213707
iteration 151 : loss : 0.781808, loss_consis: 0.022403, loss_haus: 0.049559, loss_seg: 0.254780, loss_dice: 0.766747
iteration 151 : loss : 0.781808
iteration 152 : loss : 0.207062, loss_consis: 0.030253, loss_haus: 0.061465, loss_seg: 0.135110, loss_dice: 0.188362
iteration 152 : loss : 0.207062
iteration 153 : loss : 0.246753, loss_consis: 0.023534, loss_haus: 0.063794, loss_seg: 0.172363, loss_dice: 0.227411
iteration 153 : loss : 0.246753
iteration 154 : loss : 0.396009, loss_consis: 0.012428, loss_haus: 0.052090, loss_seg: 0.101234, loss_dice: 0.380275
iteration 154 : loss : 0.396009
iteration 155 : loss : 0.114134, loss_consis: 0.019789, loss_haus: 0.047916, loss_seg: 0.057819, loss_dice: 0.099588
iteration 155 : loss : 0.114134
iteration 156 : loss : 0.212508, loss_consis: 0.023341, loss_haus: 0.043918, loss_seg: 0.086308, loss_dice: 0.199131
iteration 156 : loss : 0.212508
iteration 157 : loss : 0.359097, loss_consis: 0.019810, loss_haus: 0.052520, loss_seg: 0.129441, loss_dice: 0.343170
iteration 157 : loss : 0.359097
iteration 158 : loss : 0.448361, loss_consis: 0.017507, loss_haus: 0.053609, loss_seg: 0.135340, loss_dice: 0.432127
iteration 158 : loss : 0.448361
iteration 159 : loss : 0.128898, loss_consis: 0.017515, loss_haus: 0.040280, loss_seg: 0.083801, loss_dice: 0.116663
iteration 159 : loss : 0.128898
iteration 160 : loss : 0.513671, loss_consis: 0.026480, loss_haus: 0.042595, loss_seg: 0.345081, loss_dice: 0.500664
iteration 160 : loss : 0.513671
iteration 161 : loss : 0.240333, loss_consis: 0.027405, loss_haus: 0.073967, loss_seg: 0.248110, loss_dice: 0.217907
iteration 161 : loss : 0.240333
iteration 162 : loss : 0.169106, loss_consis: 0.020724, loss_haus: 0.038284, loss_seg: 0.091382, loss_dice: 0.157443
iteration 162 : loss : 0.169106
iteration 163 : loss : 0.638683, loss_consis: 0.026215, loss_haus: 0.071365, loss_seg: 0.187878, loss_dice: 0.617048
iteration 163 : loss : 0.638683
iteration 164 : loss : 0.084393, loss_consis: 0.023757, loss_haus: 0.053122, loss_seg: 0.087413, loss_dice: 0.068251
iteration 164 : loss : 0.084393
iteration 165 : loss : 0.401275, loss_consis: 0.027152, loss_haus: 0.057851, loss_seg: 0.173948, loss_dice: 0.383686
iteration 165 : loss : 0.401275
iteration 166 : loss : 0.506356, loss_consis: 0.026002, loss_haus: 0.063972, loss_seg: 0.166414, loss_dice: 0.486940

  1%|▏                            | 6/1072 [03:59<11:11:27, 37.79s/it]
iteration 167 : loss : 0.113709, loss_consis: 0.014930, loss_haus: 0.048926, loss_seg: 0.063524, loss_dice: 0.098902
iteration 167 : loss : 0.113709
iteration 168 : loss : 0.125661, loss_consis: 0.021056, loss_haus: 0.050004, loss_seg: 0.117946, loss_dice: 0.110479
iteration 168 : loss : 0.125661
iteration 169 : loss : 0.353646, loss_consis: 0.016067, loss_haus: 0.045814, loss_seg: 0.134742, loss_dice: 0.339764
iteration 169 : loss : 0.353646
iteration 170 : loss : 0.234055, loss_consis: 0.018318, loss_haus: 0.048777, loss_seg: 0.067273, loss_dice: 0.219264
iteration 170 : loss : 0.234055
iteration 171 : loss : 0.089140, loss_consis: 0.011713, loss_haus: 0.047936, loss_seg: 0.063231, loss_dice: 0.074658
iteration 171 : loss : 0.089140
iteration 172 : loss : 0.520815, loss_consis: 0.018494, loss_haus: 0.064135, loss_seg: 0.211465, loss_dice: 0.501415
iteration 172 : loss : 0.520815
iteration 173 : loss : 0.183215, loss_consis: 0.018901, loss_haus: 0.056860, loss_seg: 0.138937, loss_dice: 0.165994
iteration 173 : loss : 0.183215
iteration 174 : loss : 0.136166, loss_consis: 0.028654, loss_haus: 0.050063, loss_seg: 0.083926, loss_dice: 0.120900
iteration 174 : loss : 0.136166
iteration 175 : loss : 0.136282, loss_consis: 0.009902, loss_haus: 0.042374, loss_seg: 0.056007, loss_dice: 0.123485
iteration 175 : loss : 0.136282
iteration 176 : loss : 0.166061, loss_consis: 0.015700, loss_haus: 0.048090, loss_seg: 0.079365, loss_dice: 0.151498
iteration 176 : loss : 0.166061
iteration 177 : loss : 0.326949, loss_consis: 0.012928, loss_haus: 0.043195, loss_seg: 0.135152, loss_dice: 0.313879
iteration 177 : loss : 0.326949
iteration 178 : loss : 0.258623, loss_consis: 0.010399, loss_haus: 0.048781, loss_seg: 0.075990, loss_dice: 0.243899
iteration 178 : loss : 0.258623
iteration 179 : loss : 0.167348, loss_consis: 0.013673, loss_haus: 0.057686, loss_seg: 0.115798, loss_dice: 0.149925
iteration 179 : loss : 0.167348
iteration 180 : loss : 0.235926, loss_consis: 0.022714, loss_haus: 0.058771, loss_seg: 0.167881, loss_dice: 0.218098
iteration 180 : loss : 0.235926
iteration 181 : loss : 0.141706, loss_consis: 0.012249, loss_haus: 0.046686, loss_seg: 0.059950, loss_dice: 0.127595
iteration 181 : loss : 0.141706
iteration 182 : loss : 0.161878, loss_consis: 0.010890, loss_haus: 0.036469, loss_seg: 0.076628, loss_dice: 0.150844
iteration 182 : loss : 0.161878
iteration 183 : loss : 0.651902, loss_consis: 0.010214, loss_haus: 0.053030, loss_seg: 0.102340, loss_dice: 0.635905
iteration 183 : loss : 0.651902
iteration 184 : loss : 0.522608, loss_consis: 0.029213, loss_haus: 0.057419, loss_seg: 0.123465, loss_dice: 0.505130
iteration 184 : loss : 0.522608
iteration 185 : loss : 0.241608, loss_consis: 0.018984, loss_haus: 0.048313, loss_seg: 0.129790, loss_dice: 0.226950
iteration 185 : loss : 0.241608
iteration 186 : loss : 0.234499, loss_consis: 0.015957, loss_haus: 0.054538, loss_seg: 0.151783, loss_dice: 0.218000
iteration 186 : loss : 0.234499
iteration 187 : loss : 0.222278, loss_consis: 0.017074, loss_haus: 0.060831, loss_seg: 0.144511, loss_dice: 0.203882
iteration 187 : loss : 0.222278
iteration 188 : loss : 0.228186, loss_consis: 0.015128, loss_haus: 0.061288, loss_seg: 0.135095, loss_dice: 0.209669
iteration 188 : loss : 0.228186
iteration 189 : loss : 0.246631, loss_consis: 0.014647, loss_haus: 0.047216, loss_seg: 0.104717, loss_dice: 0.232339
iteration 189 : loss : 0.246631
iteration 190 : loss : 0.454951, loss_consis: 0.016946, loss_haus: 0.060315, loss_seg: 0.085678, loss_dice: 0.436710
iteration 190 : loss : 0.454951
iteration 191 : loss : 0.262044, loss_consis: 0.018328, loss_haus: 0.057916, loss_seg: 0.165368, loss_dice: 0.244511
iteration 191 : loss : 0.262044
iteration 192 : loss : 0.119760, loss_consis: 0.015351, loss_haus: 0.041414, loss_seg: 0.107942, loss_dice: 0.107203
iteration 192 : loss : 0.119760
iteration 193 : loss : 0.087787, loss_consis: 0.009706, loss_haus: 0.037077, loss_seg: 0.071039, loss_dice: 0.076580
iteration 193 : loss : 0.087787
iteration 194 : loss : 0.103826, loss_consis: 0.019256, loss_haus: 0.060475, loss_seg: 0.115902, loss_dice: 0.085517
iteration 194 : loss : 0.103826
iteration 195 : loss : 0.460945, loss_consis: 0.018508, loss_haus: 0.068278, loss_seg: 0.356354, loss_dice: 0.440302

  1%|▏                            | 7/1072 [04:32<10:44:27, 36.31s/it]
iteration 196 : loss : 0.345455, loss_consis: 0.010931, loss_haus: 0.041412, loss_seg: 0.111220, loss_dice: 0.332937
iteration 196 : loss : 0.345455
iteration 197 : loss : 0.163276, loss_consis: 0.012430, loss_haus: 0.045018, loss_seg: 0.094624, loss_dice: 0.149664
iteration 197 : loss : 0.163276
iteration 198 : loss : 0.209395, loss_consis: 0.015495, loss_haus: 0.048651, loss_seg: 0.092116, loss_dice: 0.194666
iteration 198 : loss : 0.209395
iteration 199 : loss : 0.169770, loss_consis: 0.016619, loss_haus: 0.080260, loss_seg: 0.140545, loss_dice: 0.145548
iteration 199 : loss : 0.169770
  0%|                                                                                                                                                                                                            | 0/67 [00:00<?, ?it/s]


































































 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 66/67 [02:55<00:02,  2.67s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [02:57<00:00,  2.59s/it]
iteration 200 : dice_score : 0.779786 hd95 : 27.618836
iteration 200 : loss : 0.267843, loss_consis: 0.009582, loss_haus: 0.057842, loss_seg: 0.110278, loss_dice: 0.250407
iteration 200 : loss : 0.267843
iteration 201 : loss : 0.105015, loss_consis: 0.010532, loss_haus: 0.038374, loss_seg: 0.075601, loss_dice: 0.093412
iteration 201 : loss : 0.105015
iteration 202 : loss : 0.421324, loss_consis: 0.012251, loss_haus: 0.066371, loss_seg: 0.130779, loss_dice: 0.401308
iteration 202 : loss : 0.421324
iteration 203 : loss : 0.498953, loss_consis: 0.011807, loss_haus: 0.061925, loss_seg: 0.124714, loss_dice: 0.480274
iteration 203 : loss : 0.498953
iteration 204 : loss : 0.149193, loss_consis: 0.009194, loss_haus: 0.041603, loss_seg: 0.066082, loss_dice: 0.136633
iteration 204 : loss : 0.149193
iteration 205 : loss : 0.543279, loss_consis: 0.014718, loss_haus: 0.060562, loss_seg: 0.185215, loss_dice: 0.524983
iteration 205 : loss : 0.543279
iteration 206 : loss : 0.356356, loss_consis: 0.031375, loss_haus: 0.082430, loss_seg: 0.296610, loss_dice: 0.331356
iteration 206 : loss : 0.356356
iteration 207 : loss : 0.164705, loss_consis: 0.015270, loss_haus: 0.053304, loss_seg: 0.087367, loss_dice: 0.148582
iteration 207 : loss : 0.164705
iteration 208 : loss : 0.259416, loss_consis: 0.012146, loss_haus: 0.046968, loss_seg: 0.084692, loss_dice: 0.245220
iteration 208 : loss : 0.259416
iteration 209 : loss : 0.243003, loss_consis: 0.013803, loss_haus: 0.041086, loss_seg: 0.073345, loss_dice: 0.230558
iteration 209 : loss : 0.243003
iteration 210 : loss : 0.709356, loss_consis: 0.018590, loss_haus: 0.092108, loss_seg: 0.310928, loss_dice: 0.681563
iteration 210 : loss : 0.709356
iteration 211 : loss : 0.261717, loss_consis: 0.019138, loss_haus: 0.054209, loss_seg: 0.132581, loss_dice: 0.245289
iteration 211 : loss : 0.261717
iteration 212 : loss : 0.301196, loss_consis: 0.016963, loss_haus: 0.062569, loss_seg: 0.211442, loss_dice: 0.282279
iteration 212 : loss : 0.301196
iteration 213 : loss : 0.155641, loss_consis: 0.009560, loss_haus: 0.040190, loss_seg: 0.054496, loss_dice: 0.143502
iteration 213 : loss : 0.155641
iteration 214 : loss : 0.432998, loss_consis: 0.016313, loss_haus: 0.050533, loss_seg: 0.166016, loss_dice: 0.417697
iteration 214 : loss : 0.432998
iteration 215 : loss : 0.604234, loss_consis: 0.011336, loss_haus: 0.063539, loss_seg: 0.219113, loss_dice: 0.585074
iteration 215 : loss : 0.604234
iteration 216 : loss : 0.150395, loss_consis: 0.012479, loss_haus: 0.048950, loss_seg: 0.096160, loss_dice: 0.135602
iteration 216 : loss : 0.150395
iteration 217 : loss : 0.081519, loss_consis: 0.015603, loss_haus: 0.032037, loss_seg: 0.050565, loss_dice: 0.071774
iteration 217 : loss : 0.081519
iteration 218 : loss : 0.116462, loss_consis: 0.016977, loss_haus: 0.051437, loss_seg: 0.079565, loss_dice: 0.100885
iteration 218 : loss : 0.116462
iteration 219 : loss : 0.285221, loss_consis: 0.006637, loss_haus: 0.046190, loss_seg: 0.065321, loss_dice: 0.271307
iteration 219 : loss : 0.285221
iteration 220 : loss : 0.353341, loss_consis: 0.018111, loss_haus: 0.061238, loss_seg: 0.196029, loss_dice: 0.334813
iteration 220 : loss : 0.353341
iteration 221 : loss : 0.116935, loss_consis: 0.014638, loss_haus: 0.059596, loss_seg: 0.105176, loss_dice: 0.098930
iteration 221 : loss : 0.116935
iteration 222 : loss : 0.255288, loss_consis: 0.009883, loss_haus: 0.038565, loss_seg: 0.059427, loss_dice: 0.243633
iteration 222 : loss : 0.255288
iteration 223 : loss : 0.127449, loss_consis: 0.009116, loss_haus: 0.039927, loss_seg: 0.085742, loss_dice: 0.115392
iteration 223 : loss : 0.127449
iteration 224 : loss : 0.159095, loss_consis: 0.012032, loss_haus: 0.037932, loss_seg: 0.103966, loss_dice: 0.147612

  1%|▏                            | 8/1072 [08:04<27:12:48, 92.08s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [02:57<00:00,  2.59s/it]
iteration 225 : loss : 0.541560, loss_consis: 0.016497, loss_haus: 0.080355, loss_seg: 0.234996, loss_dice: 0.517311
iteration 225 : loss : 0.541560
iteration 226 : loss : 0.166607, loss_consis: 0.018164, loss_haus: 0.059469, loss_seg: 0.114686, loss_dice: 0.148610
iteration 226 : loss : 0.166607
iteration 227 : loss : 0.097757, loss_consis: 0.016779, loss_haus: 0.038443, loss_seg: 0.052343, loss_dice: 0.086079
iteration 227 : loss : 0.097757
iteration 228 : loss : 0.285678, loss_consis: 0.009082, loss_haus: 0.056833, loss_seg: 0.062370, loss_dice: 0.268550
iteration 228 : loss : 0.285678
iteration 229 : loss : 0.109026, loss_consis: 0.013933, loss_haus: 0.052478, loss_seg: 0.062817, loss_dice: 0.093162
iteration 229 : loss : 0.109026
iteration 230 : loss : 0.717499, loss_consis: 0.009672, loss_haus: 0.061739, loss_seg: 0.123756, loss_dice: 0.698894
iteration 230 : loss : 0.717499
iteration 231 : loss : 0.586219, loss_consis: 0.021261, loss_haus: 0.045449, loss_seg: 0.142132, loss_dice: 0.572401
iteration 231 : loss : 0.586219
iteration 232 : loss : 0.321456, loss_consis: 0.021489, loss_haus: 0.040323, loss_seg: 0.058284, loss_dice: 0.309173
iteration 232 : loss : 0.321456
iteration 233 : loss : 0.123614, loss_consis: 0.015651, loss_haus: 0.058941, loss_seg: 0.136281, loss_dice: 0.105797
iteration 233 : loss : 0.123614
iteration 234 : loss : 0.181966, loss_consis: 0.014548, loss_haus: 0.045415, loss_seg: 0.093807, loss_dice: 0.168216
iteration 234 : loss : 0.181966
iteration 235 : loss : 0.164623, loss_consis: 0.012085, loss_haus: 0.042824, loss_seg: 0.115465, loss_dice: 0.151672
iteration 235 : loss : 0.164623
iteration 236 : loss : 0.307644, loss_consis: 0.012825, loss_haus: 0.053048, loss_seg: 0.118332, loss_dice: 0.291619
iteration 236 : loss : 0.307644
iteration 237 : loss : 0.191703, loss_consis: 0.017825, loss_haus: 0.039117, loss_seg: 0.061081, loss_dice: 0.179814
iteration 237 : loss : 0.191703
iteration 238 : loss : 0.288341, loss_consis: 0.017626, loss_haus: 0.060338, loss_seg: 0.134848, loss_dice: 0.270088
iteration 238 : loss : 0.288341
iteration 239 : loss : 0.065438, loss_consis: 0.008146, loss_haus: 0.031960, loss_seg: 0.047239, loss_dice: 0.055780
iteration 239 : loss : 0.065438
iteration 240 : loss : 0.283651, loss_consis: 0.008117, loss_haus: 0.041191, loss_seg: 0.036601, loss_dice: 0.271223
iteration 240 : loss : 0.283651
iteration 241 : loss : 0.153093, loss_consis: 0.012360, loss_haus: 0.053296, loss_seg: 0.065327, loss_dice: 0.136997
iteration 241 : loss : 0.153093
iteration 242 : loss : 0.100716, loss_consis: 0.012781, loss_haus: 0.046784, loss_seg: 0.054822, loss_dice: 0.086571
iteration 242 : loss : 0.100716
iteration 243 : loss : 0.220895, loss_consis: 0.015035, loss_haus: 0.069417, loss_seg: 0.172025, loss_dice: 0.199940
iteration 243 : loss : 0.220895
iteration 244 : loss : 0.229043, loss_consis: 0.012120, loss_haus: 0.064566, loss_seg: 0.137484, loss_dice: 0.209568
iteration 244 : loss : 0.229043
iteration 245 : loss : 0.208312, loss_consis: 0.013284, loss_haus: 0.043447, loss_seg: 0.068339, loss_dice: 0.195163
iteration 245 : loss : 0.208312
iteration 246 : loss : 0.146472, loss_consis: 0.007469, loss_haus: 0.035991, loss_seg: 0.031386, loss_dice: 0.135611
iteration 246 : loss : 0.146472
iteration 247 : loss : 0.197757, loss_consis: 0.008211, loss_haus: 0.054916, loss_seg: 0.111136, loss_dice: 0.181212
iteration 247 : loss : 0.197757
iteration 248 : loss : 0.182490, loss_consis: 0.013589, loss_haus: 0.056980, loss_seg: 0.097379, loss_dice: 0.165279
iteration 248 : loss : 0.182490
iteration 249 : loss : 0.197905, loss_consis: 0.009383, loss_haus: 0.044702, loss_seg: 0.079992, loss_dice: 0.184413
iteration 249 : loss : 0.197905
iteration 250 : loss : 0.116456, loss_consis: 0.010364, loss_haus: 0.040233, loss_seg: 0.054937, loss_dice: 0.104296
iteration 250 : loss : 0.116456
iteration 251 : loss : 0.260254, loss_consis: 0.011298, loss_haus: 0.048315, loss_seg: 0.083869, loss_dice: 0.245662
iteration 251 : loss : 0.260254
iteration 252 : loss : 0.506174, loss_consis: 0.010080, loss_haus: 0.052314, loss_seg: 0.303942, loss_dice: 0.490392

  1%|▏                            | 9/1072 [08:38<21:48:20, 73.85s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [02:57<00:00,  2.59s/it]
iteration 253 : loss : 0.167673, loss_consis: 0.013254, loss_haus: 0.045120, loss_seg: 0.045807, loss_dice: 0.154022
iteration 253 : loss : 0.167673
iteration 254 : loss : 0.286208, loss_consis: 0.010794, loss_haus: 0.059457, loss_seg: 0.132610, loss_dice: 0.268278
iteration 254 : loss : 0.286208
iteration 255 : loss : 0.195529, loss_consis: 0.012071, loss_haus: 0.048893, loss_seg: 0.106202, loss_dice: 0.180757
iteration 255 : loss : 0.195529
iteration 256 : loss : 0.102229, loss_consis: 0.007343, loss_haus: 0.049885, loss_seg: 0.057798, loss_dice: 0.087200
iteration 256 : loss : 0.102229
iteration 257 : loss : 0.289898, loss_consis: 0.013809, loss_haus: 0.061278, loss_seg: 0.206531, loss_dice: 0.271396
iteration 257 : loss : 0.289898
iteration 258 : loss : 0.269403, loss_consis: 0.011421, loss_haus: 0.059376, loss_seg: 0.161106, loss_dice: 0.251492
iteration 258 : loss : 0.269403
iteration 259 : loss : 0.337929, loss_consis: 0.027862, loss_haus: 0.065704, loss_seg: 0.158640, loss_dice: 0.317977
iteration 259 : loss : 0.337929
iteration 260 : loss : 0.092627, loss_consis: 0.012684, loss_haus: 0.047322, loss_seg: 0.036489, loss_dice: 0.078321
iteration 260 : loss : 0.092627
iteration 261 : loss : 0.226878, loss_consis: 0.016892, loss_haus: 0.044183, loss_seg: 0.103600, loss_dice: 0.213478
iteration 261 : loss : 0.226878
iteration 262 : loss : 0.566415, loss_consis: 0.021315, loss_haus: 0.041173, loss_seg: 0.150706, loss_dice: 0.553879
iteration 262 : loss : 0.566415
iteration 263 : loss : 0.261103, loss_consis: 0.010421, loss_haus: 0.064021, loss_seg: 0.166686, loss_dice: 0.241806
iteration 263 : loss : 0.261103
iteration 264 : loss : 0.432375, loss_consis: 0.014340, loss_haus: 0.049860, loss_seg: 0.101820, loss_dice: 0.417293
iteration 264 : loss : 0.432375
iteration 265 : loss : 0.355895, loss_consis: 0.013779, loss_haus: 0.046413, loss_seg: 0.078221, loss_dice: 0.341852
iteration 265 : loss : 0.355895
iteration 266 : loss : 0.112488, loss_consis: 0.010361, loss_haus: 0.036158, loss_seg: 0.073080, loss_dice: 0.101551
iteration 266 : loss : 0.112488
iteration 267 : loss : 0.118775, loss_consis: 0.016754, loss_haus: 0.051253, loss_seg: 0.084272, loss_dice: 0.103255
iteration 267 : loss : 0.118775
iteration 268 : loss : 0.472320, loss_consis: 0.015872, loss_haus: 0.071602, loss_seg: 0.251455, loss_dice: 0.450703
iteration 268 : loss : 0.472320
iteration 269 : loss : 0.405848, loss_consis: 0.007658, loss_haus: 0.034178, loss_seg: 0.085133, loss_dice: 0.395528
iteration 269 : loss : 0.405848
iteration 270 : loss : 0.177700, loss_consis: 0.010722, loss_haus: 0.044679, loss_seg: 0.065361, loss_dice: 0.164203
iteration 270 : loss : 0.177700
iteration 271 : loss : 0.105865, loss_consis: 0.013949, loss_haus: 0.042318, loss_seg: 0.083148, loss_dice: 0.093050
iteration 271 : loss : 0.105865
iteration 272 : loss : 0.144988, loss_consis: 0.019448, loss_haus: 0.045762, loss_seg: 0.096185, loss_dice: 0.131091
iteration 272 : loss : 0.144988
iteration 273 : loss : 0.123522, loss_consis: 0.039612, loss_haus: 0.080428, loss_seg: 0.086300, loss_dice: 0.099052
iteration 273 : loss : 0.123522
iteration 274 : loss : 0.484018, loss_consis: 0.012432, loss_haus: 0.065843, loss_seg: 0.209894, loss_dice: 0.464158
iteration 274 : loss : 0.484018
iteration 275 : loss : 0.413386, loss_consis: 0.020037, loss_haus: 0.059355, loss_seg: 0.107047, loss_dice: 0.395407
iteration 275 : loss : 0.413386
iteration 276 : loss : 0.158339, loss_consis: 0.012368, loss_haus: 0.051171, loss_seg: 0.107419, loss_dice: 0.142881
iteration 276 : loss : 0.158339
iteration 277 : loss : 0.221650, loss_consis: 0.010061, loss_haus: 0.047599, loss_seg: 0.093682, loss_dice: 0.207284
iteration 277 : loss : 0.221650
iteration 278 : loss : 0.545504, loss_consis: 0.008141, loss_haus: 0.060660, loss_seg: 0.072547, loss_dice: 0.527236
iteration 278 : loss : 0.545504
iteration 279 : loss : 0.157160, loss_consis: 0.010417, loss_haus: 0.041347, loss_seg: 0.067441, loss_dice: 0.144666

  1%|▎                           | 10/1072 [09:12<18:08:43, 61.51s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [02:57<00:00,  2.59s/it]
iteration 280 : loss : 0.179203, loss_consis: 0.013713, loss_haus: 0.044125, loss_seg: 0.066011, loss_dice: 0.165847
iteration 280 : loss : 0.179203
iteration 281 : loss : 0.230241, loss_consis: 0.029387, loss_haus: 0.067633, loss_seg: 0.158140, loss_dice: 0.209697
iteration 281 : loss : 0.230241
iteration 282 : loss : 0.233436, loss_consis: 0.013281, loss_haus: 0.062889, loss_seg: 0.139114, loss_dice: 0.214454
iteration 282 : loss : 0.233436
iteration 283 : loss : 0.134116, loss_consis: 0.008898, loss_haus: 0.048452, loss_seg: 0.087211, loss_dice: 0.119504
iteration 283 : loss : 0.134116
iteration 284 : loss : 0.153716, loss_consis: 0.012571, loss_haus: 0.042753, loss_seg: 0.085779, loss_dice: 0.140782
iteration 284 : loss : 0.153716
iteration 285 : loss : 0.169108, loss_consis: 0.011045, loss_haus: 0.035849, loss_seg: 0.035619, loss_dice: 0.158258
iteration 285 : loss : 0.169108
iteration 286 : loss : 0.239807, loss_consis: 0.012806, loss_haus: 0.060682, loss_seg: 0.082955, loss_dice: 0.221492
iteration 286 : loss : 0.239807
iteration 287 : loss : 0.099146, loss_consis: 0.016792, loss_haus: 0.042445, loss_seg: 0.062214, loss_dice: 0.086267
iteration 287 : loss : 0.099146
iteration 288 : loss : 0.212683, loss_consis: 0.015879, loss_haus: 0.049669, loss_seg: 0.097745, loss_dice: 0.197646
iteration 288 : loss : 0.212683
iteration 289 : loss : 0.113638, loss_consis: 0.016804, loss_haus: 0.049444, loss_seg: 0.053620, loss_dice: 0.098660
iteration 289 : loss : 0.113638
iteration 290 : loss : 0.141466, loss_consis: 0.015660, loss_haus: 0.038534, loss_seg: 0.084379, loss_dice: 0.129771
iteration 290 : loss : 0.141466
iteration 291 : loss : 0.135484, loss_consis: 0.017912, loss_haus: 0.042893, loss_seg: 0.058114, loss_dice: 0.122461
iteration 291 : loss : 0.135484
iteration 292 : loss : 0.354418, loss_consis: 0.013013, loss_haus: 0.051018, loss_seg: 0.041425, loss_dice: 0.339000
iteration 292 : loss : 0.354418
iteration 293 : loss : 0.224035, loss_consis: 0.010466, loss_haus: 0.036387, loss_seg: 0.076898, loss_dice: 0.213029
iteration 293 : loss : 0.224035
iteration 294 : loss : 0.246540, loss_consis: 0.011895, loss_haus: 0.056219, loss_seg: 0.062212, loss_dice: 0.229572
iteration 294 : loss : 0.246540
iteration 295 : loss : 0.180622, loss_consis: 0.014256, loss_haus: 0.042984, loss_seg: 0.066204, loss_dice: 0.167604
iteration 295 : loss : 0.180622
iteration 296 : loss : 0.155307, loss_consis: 0.014521, loss_haus: 0.102226, loss_seg: 0.072213, loss_dice: 0.124514
iteration 296 : loss : 0.155307
iteration 297 : loss : 0.530397, loss_consis: 0.018653, loss_haus: 0.061568, loss_seg: 0.130988, loss_dice: 0.511766
iteration 297 : loss : 0.530397
iteration 298 : loss : 0.158500, loss_consis: 0.007211, loss_haus: 0.041190, loss_seg: 0.051614, loss_dice: 0.146081
iteration 298 : loss : 0.158500
iteration 299 : loss : 0.198719, loss_consis: 0.013054, loss_haus: 0.044889, loss_seg: 0.070753, loss_dice: 0.185140
iteration 299 : loss : 0.198719
iteration 300 : loss : 0.290051, loss_consis: 0.010620, loss_haus: 0.052044, loss_seg: 0.084542, loss_dice: 0.274347
iteration 300 : loss : 0.290051
iteration 301 : loss : 0.151276, loss_consis: 0.020857, loss_haus: 0.051980, loss_seg: 0.132319, loss_dice: 0.135453
iteration 301 : loss : 0.151276
iteration 302 : loss : 0.095722, loss_consis: 0.012562, loss_haus: 0.042467, loss_seg: 0.055469, loss_dice: 0.082844
iteration 302 : loss : 0.095722
iteration 303 : loss : 0.272637, loss_consis: 0.018261, loss_haus: 0.055947, loss_seg: 0.168414, loss_dice: 0.255653
iteration 303 : loss : 0.272637
iteration 304 : loss : 0.080857, loss_consis: 0.010984, loss_haus: 0.042793, loss_seg: 0.033364, loss_dice: 0.067899
iteration 304 : loss : 0.080857
iteration 305 : loss : 0.136386, loss_consis: 0.019404, loss_haus: 0.047844, loss_seg: 0.067993, loss_dice: 0.121820
iteration 305 : loss : 0.136386
iteration 306 : loss : 0.241951, loss_consis: 0.014505, loss_haus: 0.050338, loss_seg: 0.146995, loss_dice: 0.226691
iteration 306 : loss : 0.241951
iteration 307 : loss : 0.219756, loss_consis: 0.013741, loss_haus: 0.052440, loss_seg: 0.097983, loss_dice: 0.203873

  1%|▎                           | 11/1072 [09:45<15:34:01, 52.82s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [02:57<00:00,  2.59s/it]
iteration 308 : loss : 0.484315, loss_consis: 0.016164, loss_haus: 0.059791, loss_seg: 0.141171, loss_dice: 0.466200
iteration 308 : loss : 0.484315
iteration 309 : loss : 0.164588, loss_consis: 0.012559, loss_haus: 0.042141, loss_seg: 0.067475, loss_dice: 0.151808
iteration 309 : loss : 0.164588
iteration 310 : loss : 0.233483, loss_consis: 0.027160, loss_haus: 0.070127, loss_seg: 0.257191, loss_dice: 0.212147
iteration 310 : loss : 0.233483
iteration 311 : loss : 0.266473, loss_consis: 0.017519, loss_haus: 0.051982, loss_seg: 0.098771, loss_dice: 0.250687
iteration 311 : loss : 0.266473
iteration 312 : loss : 0.163958, loss_consis: 0.049860, loss_haus: 0.069382, loss_seg: 0.162857, loss_dice: 0.142596
iteration 312 : loss : 0.163958
iteration 313 : loss : 0.289384, loss_consis: 0.017902, loss_haus: 0.045746, loss_seg: 0.046849, loss_dice: 0.275463
iteration 313 : loss : 0.289384
iteration 314 : loss : 0.079064, loss_consis: 0.017895, loss_haus: 0.045362, loss_seg: 0.053184, loss_dice: 0.065259
iteration 314 : loss : 0.079064
iteration 315 : loss : 0.500499, loss_consis: 0.019764, loss_haus: 0.058169, loss_seg: 0.087555, loss_dice: 0.482831
  1%|▎                           | 11/1072 [09:56<15:58:21, 54.20s/it]██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [02:57<00:00,  2.59s/it]
Traceback (most recent call last):
  File "Brats_train_dtc_original_kfold.py", line 223, in <module>
    writer.add_scalar('loss/loss', loss, iter_num)
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/tensorboardX/writer.py", line 457, in add_scalar
    scalar(tag, scalar_value, display_name, summary_description), global_step, walltime)
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/tensorboardX/summary.py", line 152, in scalar
    scalar = make_np(scalar)
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/tensorboardX/x2num.py", line 28, in make_np
    return check_nan(prepare_pytorch(x))
  File "/home/sohui/miniconda3/envs/test/lib/python3.8/site-packages/tensorboardX/x2num.py", line 43, in prepare_pytorch
    x = x.cpu().numpy()
KeyboardInterrupt
iteration 316 : loss : 0.366756, loss_consis: 0.017272, loss_haus: 0.075994, loss_seg: 0.171331, loss_dice: 0.343768
iteration 316 : loss : 0.366756